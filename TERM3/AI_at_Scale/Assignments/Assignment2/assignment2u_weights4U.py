# -*- coding: utf-8 -*-
"""Assignment2U_weights.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/aymuos/masters-practise-repo/blob/main/TERM3/AI_at_Scale/Assignments/Assignment2/Assignment2U_weights.ipynb
"""

# !pip install pyspark pandas imbalanced-learn

"""Use the Bank Marketing dataset (saved in drive) to build a binary
classifier that predicts whether a customer will subscribe to a term deposit
using Spark MLlib.


Do the following tasks on the dataset:


Problem 1 : Data Understanding (Marks : 10)
"""

from pyspark.sql import SparkSession
import pandas as pd
from pyspark.sql.functions import regexp_replace, col, countDistinct, col, sum as spark_sum
from pyspark.sql.functions import count, when, lit, create_map
from pyspark.sql.types import StringType, DoubleType, IntegerType ,StructType,StructField
from pyspark.ml.feature import Imputer, VectorAssembler,StandardScaler
from pyspark.ml.tuning import CrossValidator,ParamGridBuilder
import time
from pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor
from pyspark.ml import PipelineModel

# import csv

# def sniff_delimiter(file_path):
#     with open(file_path, 'r') as f:
#         # Read a sample of the file
#         sample = f.read(4096)
#         # Use the sniffer to guess the delimiter
#         sniffer = csv.Sniffer()
#         try:
#             dialect = sniffer.sniff(sample)
#             return dialect.delimiter
#         except csv.Error:
#             return "Could not determine delimiter automatically. Please inspect the file manually."

# file_path = 'bank-full.csv'
# delimiter = sniff_delimiter(file_path)
# print(f"Detected delimiter: {delimiter}")

def get_schema():
    return StructType([
    StructField("age", IntegerType(), True),
    StructField("job", StringType(), True),
    StructField("marital", StringType(), True),
    StructField("education", StringType(), True),
    StructField("default", StringType(), True),
    StructField("balance", DoubleType(), True),
    StructField("housing", StringType(), True),
    StructField("loan", StringType(), True),
    StructField("contact", StringType(), True),
    StructField("day", IntegerType(), True),
    StructField("month", StringType(), True),
    StructField("duration", IntegerType(), True),
    StructField("campaign", IntegerType(), True),
    StructField("pdays", IntegerType(), True),
    StructField("previous", IntegerType(), True),
    StructField("poutcome", StringType(), True),
    StructField("y", StringType(), True)

])

# Load the dataset and print schema
def create_spark_session(executor_cores="1", max_cores="2", executor_memory="1g"):
    return SparkSession.builder \
        .appName("Assignment2_ch24m571") \
        .config("spark.executor.cores", executor_cores) \
        .config("spark.cores.max", max_cores) \
        .config("spark.executor.memory", executor_memory) \
        .config("spark.driver.memory", "2g") \
        .getOrCreate()
# spark_c = SparkSession.builder \
#     .appName("Assignment2") \
#     .config("spark.executor.cores","2") \
#     .config("spark.executor.memory", "1g") \
#     .config("spark.driver.memory", "2g") \
#     .getOrCreate()

# data = spark_c.read.csv("bank-full.csv", header=True, schema=customSchema, sep=';')
# data.printSchema()

# data.show()

''' Use your favorite strategy to balance the dataset, if you find that data is imbalanced
and is important to balance the dataset before training the model. Provide
explanation of your decision. '''

def apply_class_weights(spark,train_df):
  ''' Calculate and apply class weights based on the inverse of class frequencies.
  '''
  try:
    # Calculate class counts
    train_counts = train_df.groupBy("y").count().collect()
    yes_count = [row['count'] for row in train_counts if row['y'] == 'yes'][0]
    no_count = [row['count'] for row in train_counts if row['y'] == 'no'][0]
    total_train_count = train_df.count()

    # Calculate class weights
    class_weight_no = total_train_count / (2 * no_count)
    class_weight_yes = total_train_count / (2 * yes_count)

    print(f"Calculated class weight for 'no': {class_weight_no:.4f}")
    print(f"Calculated class weight for 'yes': {class_weight_yes:.4f}")

    # Map class labels to weights and add 'classWeight' column
    mapping_expr = create_map(lit("no"), lit(class_weight_no), lit("yes"), lit(class_weight_yes))
    train_df_with_weights = train_df.withColumn("classWeight", mapping_expr.getItem(col("y")))

    print("Class weights applied to the training DataFrame.")
    return train_df_with_weights, True
  except Exception as e:
    print(f"Error applying class weights: {str(e)}")
    return train_df, False

def problem_1_eda(spark , data_path ):
  ''' Question 1 '''
  print("**********************************************")
  # 1. Load dataset and print schema
  print("1. Loading dataset and printing schema:")

  customSchema = get_schema()
  data = spark.read.csv(data_path, header=True, schema=customSchema, sep=';')
  data.printSchema()

  # 1a. Check and remove rows with null 'y' values
  print("\n1a. Checking for and removing rows with null 'y' values:")
  initial_count = data.count()
  data = data.na.drop(subset=["y"])
  rows_removed = initial_count - data.count()
  print(f"Initial row count: {initial_count}")
  print(f"Rows removed due to null 'y': {rows_removed}")
  print(f"Row count after removing null 'y': {data.count()}")


  # 2. Count subscriptions
  print("\n2. Subscription counts:")
  subscription_counts = data.groupBy("y").count().orderBy("y")
  subscription_counts.show()



  # 3. Print distinct values for job and education
  print("\n3. Distinct values and counts for 'job':")
  data.groupBy("job").count().orderBy("count", ascending=False).show(truncate=False)

  print("Distinct values and counts for 'education':")
  data.groupBy("education").count().orderBy("count", ascending=False).show(truncate=False)



  # 4. Split data and report distribution
  print("\n4. Splitting data into train and test sets:")
  train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)

  print(f"Training set size: {train_df.count()}")
  print(f"Test set size: {test_df.count()}")

  print("\nDistribution in training set:")
  train_df.groupBy("y").count().orderBy("y").show()

  print("Distribution in test set:")
  test_df.groupBy("y").count().orderBy("y").show()



  # 5. Check class imbalance and calculate class weights
  print("\n5. Class imbalance analysis and class weight calculation:")
  train_counts = train_df.groupBy("y").count().collect()
  yes_count = [row['count'] for row in train_counts if row['y'] == 'yes'][0]
  no_count = [row['count'] for row in train_counts if row['y'] == 'no'][0]

  total_train_count = train_df.count()
  class_weight_no = total_train_count / (2 * no_count)
  class_weight_yes = total_train_count / (2 * yes_count)

  print(f"Imbalance ratio (no/yes): {no_count / yes_count:.2f}")
  print(f"Class weight for 'no': {class_weight_no:.4f}")
  print(f"Class weight for 'yes': {class_weight_yes:.4f}")

  # Map class labels to weights
  mapping_expr = create_map(lit("no"), lit(class_weight_no), lit("yes"), lit(class_weight_yes))
  train_df_with_weights = train_df.withColumn("classWeight", mapping_expr.getItem(col("y")))

  return data, train_df_with_weights, test_df

"""Data is heavily imbalanced , hence need to balance

Initially used smoteenc but since the server doesnot allow additional packages to be install , cant install imbalanced-learn , hence going with class weights

Q2--------------
"""

# Use StringIndexer and OneHotEncoder on all categorical features.

from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
def problem_2_data_preprocessing(train_df, test_df):
    """Problem 2: Data Preprocessing"""

    print("PROBLEM 2: DATA PREPROCESSING")

    categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']
    numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']

    indexers = [StringIndexer(inputCol=col, outputCol=f"{col}_indexed", handleInvalid="keep")
                    for col in categorical_columns]

    encoders = [OneHotEncoder(inputCol=f"{col}_indexed", outputCol=f"{col}_encoded")
                    for col in categorical_columns]


    # Assemble all features using VectorAssembler.

    feature_cols = numerical_columns + [f"{col}_encoded" for col in categorical_columns]
    assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")

    # Use StringIndexer on the label column y.
    label_indexer = StringIndexer(inputCol="y", outputCol="label")

    return indexers, encoders, assembler, label_indexer, feature_cols

"""Q3"""

'''
Problem 3: Model Building (Marks : 10)
1. Build a pipeline using Logistic Regression.
2. Train a random forest.
3. Evaluate using accuracy, precision, and recall.
4. Print the name of the best model and show confusion matrix for the best model.
'''
from pyspark.ml.classification import LogisticRegression, RandomForestClassifier
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
from pyspark.mllib.evaluation import MulticlassMetrics

def problem_3_model_building(train_df, test_df, indexers, encoders, assembler, label_indexer):
  # 1. LR model

  lr = LogisticRegression(featuresCol="features", labelCol="label", weightCol="classWeight")
  lr_pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer, lr])

  print("Training Logistic Regression model...")

  start_time = time.time()
  lr_model = lr_pipeline.fit(train_df)
  lr_train_time = time.time() - start_time
  print(f"Logistic Regression training time: {lr_train_time:.2f} seconds")


  # 2. Random Forest
  rf = RandomForestClassifier(featuresCol="features", labelCol="label", weightCol="classWeight",
                              numTrees=10, seed=42)
  rf_pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer, rf])

  print("Training Random Forest model...")
  start_time = time.time()
  rf_model = rf_pipeline.fit(train_df)
  rf_train_time = time.time() - start_time
  print(f"Random Forest training time: {rf_train_time:.2f} seconds")




  # 3. Evaluate models
  print("\n3. Model Evaluation:")

  # Predictions
  lr_predictions = lr_model.transform(test_df)
  rf_predictions = rf_model.transform(test_df)

  # Evaluators
  accuracy_evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction",metricName="accuracy")
  precision_evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction",metricName="weightedPrecision")
  recall_evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction",metricName="weightedRecall")

  # Calculate metrics
  models_metrics = {}

  for name, predictions in [("Logistic Regression", lr_predictions), ("Random Forest", rf_predictions)]:
      accuracy = accuracy_evaluator.evaluate(predictions)
      precision = precision_evaluator.evaluate(predictions)
      recall = recall_evaluator.evaluate(predictions)

      models_metrics[name] = {
          'accuracy': accuracy,
          'precision': precision,
          'recall': recall
      }

      print(f"\n{name} Metrics:")
      print(f"Accuracy: {accuracy:.4f}")
      print(f"Precision: {precision:.4f}")
      print(f"Recall: {recall:.4f}")
  # 4. Find best model and show confusion matrix
  best_model_name = max(models_metrics.keys(), key=lambda x: models_metrics[x]['accuracy'])
  print(f"\nBest model: {best_model_name}")

  best_predictions = lr_predictions if best_model_name == "Logistic Regression" else rf_predictions

  # Confusion Matrix
  print(f"\nConfusion Matrix for {best_model_name}:")
  predictionAndLabels = best_predictions.select("prediction", "label").rdd.map(lambda x: (float(x[0]), float(x[1])))
  metrics = MulticlassMetrics(predictionAndLabels)
  confusion_matrix = metrics.confusionMatrix().toArray()
  print(confusion_matrix)

  return lr_model, rf_model, models_metrics, best_model_name

"""Q4 : Hyper parameter tuning"""

'''Problem 4: Hyperparameter tuning and parallelism (Marks : 10)
      1. Select hyperparameters for tuning and their values and justify your selection
      2. Perform cross validation for random forest.

      3. Compare the accuracy results of logistic regression, random forest without hyper-
      parameter tuning, random forest with hyperparameter tuning models.
'''

def problem_4_hyperparameter_tuning(train_df, test_df, indexers, encoders, assembler, label_indexer, models_metrics):
    """Problem 4: Hyperparameter Tuning and Parallelism"""
    print("PROBLEM 4: HYPERPARAMETER TUNING")

    # 1. Select hyperparameters for Random Forest
    print("1. Hyperparameter selection for Random Forest:")

    rf = RandomForestClassifier(featuresCol="features", labelCol="label", weightCol="classWeight", seed=42)
    rf_pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer, rf])

    # Parameter grid
    paramGrid = ParamGridBuilder() \
        .addGrid(rf.numTrees, [10, 20]) \
        .addGrid(rf.maxDepth, [5, 10]) \
        .addGrid(rf.minInstancesPerNode, [5, 10]) \
        .build()

    # 2. Cross validation
    print(f"\n2. Performing cross-validation with {len(paramGrid)} parameter combinations and reduced folds...")

    evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction",
                                                 metricName="accuracy")

    crossval = CrossValidator(estimator=rf_pipeline,
                             estimatorParamMaps=paramGrid,
                             evaluator=evaluator,
                             numFolds=2,
                             seed=42)

    start_time = time.time()
    cv_model = crossval.fit(train_df)
    cv_train_time = time.time() - start_time
    print(f"Cross-validation training time: {cv_train_time:.2f} seconds")

    # Best model evaluation
    best_rf_predictions = cv_model.transform(test_df)
    best_rf_accuracy = evaluator.evaluate(best_rf_predictions)

    # 3. Compare accuracies
    print("\n3. Accuracy Comparison:")
    print(f"Logistic Regression: {models_metrics['Logistic Regression']['accuracy']:.4f}")
    print(f"Random Forest (no tuning): {models_metrics['Random Forest']['accuracy']:.4f}")
    print(f"Random Forest (with hyperparameter tuning): {best_rf_accuracy:.4f}")

    return cv_model, best_rf_accuracy

import time
from pyspark.sql import SparkSession
from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
import pandas as pd


# DEFINED BUT NOT USED - INSTEAD INDIVIDUAL PERFORMANCE PROFILING WORKS
def problem_5_performance_profiling():
    print("PROBLEM 5: PERFORMANCE PROFILING")


    configurations = [
        {"executor_cores": "1", "max_cores": "2", "executor_memory": "1g", "parallelism": None},
        {"executor_cores": "2", "max_cores": "2", "executor_memory": "1g", "parallelism": None},
        {"executor_cores": "2", "max_cores": "2", "executor_memory": "1g", "parallelism": "1"},
        {"executor_cores": "2", "max_cores": "2", "executor_memory": "1g", "parallelism": "2"}
    ]

    results = []

    for i, config in enumerate(configurations):
        print(f"\nConfiguration {i+1}: {config}")
        spark = create_spark_session(config["executor_cores"], config["max_cores"], config["executor_memory"])

        if config["parallelism"]:
            spark.conf.set("spark.sql.adaptive.coalescePartitions.parallelismFirst", "true")
            spark.conf.set("spark.default.parallelism", config["parallelism"])

        times = {}
        config_label = f"Cores: {config['executor_cores']}, Max: {config['max_cores']}, Mem: {config['executor_memory']}"
        if config['parallelism']:
            config_label += f", Parallelism: {config['parallelism']}"
        config_results = {'Configuration': config_label}

        try:
            start_time = time.time()
            student_id = "CH24M571"  # your roll number, letters must be in capital letter
            app_name = student_id + "_Assignment_2_PERFORMANCE_PROFILE"
            assignment_no = "Assignment_2"

            data_path = f"/opt/spark/data/{student_id}/"

            # data_path = "bank-full.csv"
            schema = get_schema()

            data = spark.read.csv(data_path, header=True, schema=schema, sep=';')
            train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)
            times['Data Loading'] = time.time() - start_time

        except Exception as e:
            config_results['Data Loading Error'] = str(e)
            spark.stop()
            results.append(config_results)
            continue

        try:
            start_time = time.time()
            categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']
            numerical_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']

            indexers = [StringIndexer(inputCol=col, outputCol=f"{col}_indexed", handleInvalid="keep") for col in categorical_cols]
            encoders = [OneHotEncoder(inputCol=f"{col}_indexed", outputCol=f"{col}_encoded") for col in categorical_cols]

            feature_cols = numerical_cols + [f"{col}_encoded" for col in categorical_cols]

            assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")
            label_indexer = StringIndexer(inputCol="y", outputCol="label")

            pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer])
            preproc_model = pipeline.fit(train_df)
            train_df_processed = preproc_model.transform(train_df)
            test_df_processed = preproc_model.transform(test_df)
            times['Preprocessing'] = time.time() - start_time
        except Exception as e:
            config_results['Preprocessing Error'] = str(e)
            spark.stop()
            results.append(config_results)
            continue

        try:
            start_time = time.time()
            rf = RandomForestClassifier(featuresCol="features", labelCol="label", numTrees=10, seed=42)
            model = rf.fit(train_df_processed)
            times['Model Training'] = time.time() - start_time
        except Exception as e:
            config_results['Model Training Error'] = str(e)
            spark.stop()
            results.append(config_results)
            continue

        try:
            start_time = time.time()
            predictions = model.transform(test_df_processed)
            evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
            accuracy = evaluator.evaluate(predictions)
            times['Model Evaluation'] = time.time() - start_time
            times['Accuracy'] = accuracy
        except Exception as e:
            config_results['Model Evaluation Error'] = str(e)
            spark.stop()
            results.append(config_results)
            continue

        try:
            # FIX: Use Python's built-in sum
            total_time = 0.0
            for k, v in times.items():
                if k != 'Accuracy' and isinstance(v, (int, float)):
                    total_time += v
            times['Total Time'] = total_time
            config_results.update(times)
        except Exception as e:
            config_results['Total Time Calculation Error'] = str(e)

        results.append(config_results)
        spark.stop()

    # Convert to Pandas DataFrame for better table printing
    df_results = pd.DataFrame(results)
    print("\n=== Performance Results Table ===")
    print(df_results.to_string(index=False))

"""MAIN FUNCTION OF CODE"""

def main():
  ''' Main'''
# Initialize Spark session
  spark = create_spark_session()
  try:

    student_id = "CH24M571"  # your roll number, letters must be in capital letter
    app_name = student_id + "_Assignment_2_PERFORMANCE_PROFILE"
    assignment_no = "Assignment_2_pp"

    data_path = f"/opt/spark/data/{student_id}/"
    # data_path = 'bank-full.csv'

    # Problem 1: Data Understanding
    data, train_df, test_df = problem_1_eda(spark, data_path)

    # Problem 2: Data Preprocessing
    indexers, encoders, assembler, label_indexer, feature_cols = problem_2_data_preprocessing(train_df, test_df)

    # Problem 3: Model Building
    lr_model, rf_model, models_metrics, best_model_name = problem_3_model_building(
        train_df, test_df, indexers, encoders, assembler, label_indexer)

    # Problem 4: Hyperparameter Tuning
    cv_model, best_rf_accuracy = problem_4_hyperparameter_tuning(
        train_df, test_df, indexers, encoders, assembler, label_indexer, models_metrics)

  except Exception as e:
    print(f"Error in main execution: {str(e)}")

  finally:
    spark.stop()

main()

# problem_5_performance_profiling()

# def run_single_performance_profiling(config):
#     """Runs performance profiling for a single Spark configuration."""
#     print(f"\nConfiguration: {config}")
#     spark = create_spark_session(config["executor_cores"], config["max_cores"], config["executor_memory"])

#     if config["parallelism"]:
#         spark.conf.set("spark.sql.adaptive.coalescePartitions.parallelismFirst", "true")
#         spark.conf.set("spark.default.parallelism", config["parallelism"])

#     times = {}
#     config_label = f"Cores: {config['executor_cores']}, Max: {config['max_cores']}, Mem: {config['executor_memory']}"
#     if config['parallelism']:
#         config_label += f", Parallelism: {config['parallelism']}"
#     config_results = {'Configuration': config_label}

#     try:
#         start_time = time.time()
#         data_path = "bank-full.csv"
#         schema = get_schema()
#         data = spark.read.csv(data_path, header=True, schema=schema, sep=';')
#         train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)
#         times['Data Loading'] = time.time() - start_time
#     except Exception as e:
#         config_results['Data Loading Error'] = str(e)
#         spark.stop()
#         return config_results

#     try:
#         start_time = time.time()
#         categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']
#         numerical_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']

#         indexers = [StringIndexer(inputCol=col, outputCol=f"{col}_indexed", handleInvalid="keep") for col in categorical_cols]
#         encoders = [OneHotEncoder(inputCol=f"{col}_indexed", outputCol=f"{col}_encoded") for col in categorical_cols]

#         feature_cols = numerical_cols + [f"{col}_encoded" for col in categorical_cols]

#         assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")
#         label_indexer = StringIndexer(inputCol="y", outputCol="label")

#         pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer])
#         preproc_model = pipeline.fit(train_df)
#         train_df_processed = preproc_model.transform(train_df)
#         test_df_processed = preproc_model.transform(test_df)
#         times['Preprocessing'] = time.time() - start_time
#     except Exception as e:
#         config_results['Preprocessing Error'] = str(e)
#         spark.stop()
#         return config_results

#     try:
#         start_time = time.time()
#         rf = RandomForestClassifier(featuresCol="features", labelCol="label", numTrees=10, seed=42)
#         model = rf.fit(train_df_processed)
#         times['Model Training'] = time.time() - start_time
#     except Exception as e:
#         config_results['Model Training Error'] = str(e)
#         spark.stop()
#         return config_results

#     try:
#         start_time = time.time()
#         predictions = model.transform(test_df_processed)
#         evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
#         accuracy = evaluator.evaluate(predictions)
#         times['Model Evaluation'] = time.time() - start_time
#         times['Accuracy'] = accuracy
#     except Exception as e:
#         config_results['Model Evaluation Error'] = str(e)
#         spark.stop()
#         return config_results

#     try:
#         total_time = 0.0
#         for k, v in times.items():
#             if k != 'Accuracy' and isinstance(v, (int, float)):
#                 total_time += v
#         times['Total Time'] = total_time
#         config_results.update(times)
#     except Exception as e:
#         config_results['Total Time Calculation Error'] = str(e)

#     spark.stop()
#     return config_results

"""Here's how you can call the `run_single_performance_profiling` function with different configurations:"""

# # Example usage:

# # Configuration 1
# config1 = {"executor_cores": "1", "max_cores": "2", "executor_memory": "1g", "parallelism": None}
# results1 = run_single_performance_profiling(config1)
# print("\nResults for Configuration 1:")
# print(pd.DataFrame([results1]).to_string(index=False))

# # Configuration 2
# config2 = {"executor_cores": "2", "max_cores": "2", "executor_memory": "1g", "parallelism": None}
# results2 = run_single_performance_profiling(config2)
# print("\nResults for Configuration 2:")
# print(pd.DataFrame([results2]).to_string(index=False))

# # Configuration 3
# config3 = {"executor_cores": "2", "max_cores": "2", "executor_memory": "1g", "parallelism": "1"}
# results3 = run_single_performance_profiling(config3)
# print("\nResults for Configuration 3:")
# print(pd.DataFrame([results3]).to_string(index=False))

# # Configuration 4
# config4 = {"executor_cores": "2", "max_cores": "2", "executor_memory": "1g", "parallelism": "2"}
# results4 = run_single_performance_profiling(config4)
# print("\nResults for Configuration 4:")
# print(pd.DataFrame([results4]).to_string(index=False))