{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymuos/masters-practise-repo/blob/main/TERM3/AI_at_Scale/Assignments/Assignment2/Assignment2U_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cBC68pZCaSow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4340ffa0-cf0b-4d94-965e-2815d97615b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark pandas imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the Bank Marketing dataset (saved in drive) to build a binary\n",
        "classifier that predicts whether a customer will subscribe to a term deposit\n",
        "using Spark MLlib.\n",
        "\n",
        "\n",
        "Do the following tasks on the dataset:\n",
        "\n",
        "\n",
        "Problem 1 : Data Understanding (Marks : 10)"
      ],
      "metadata": {
        "id": "W7fzCKr8sYSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import regexp_replace, col, countDistinct, col, sum as spark_sum\n",
        "from pyspark.sql.functions import count, when, lit, create_map\n",
        "from pyspark.sql.types import StringType, DoubleType, IntegerType ,StructType,StructField\n",
        "from pyspark.ml.feature import Imputer, VectorAssembler,StandardScaler\n",
        "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
        "import time\n",
        "from pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor\n",
        "from pyspark.ml import PipelineModel"
      ],
      "metadata": {
        "id": "98UUQTdqtgxG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e3829ee"
      },
      "source": [
        "# import csv\n",
        "\n",
        "# def sniff_delimiter(file_path):\n",
        "#     with open(file_path, 'r') as f:\n",
        "#         # Read a sample of the file\n",
        "#         sample = f.read(4096)\n",
        "#         # Use the sniffer to guess the delimiter\n",
        "#         sniffer = csv.Sniffer()\n",
        "#         try:\n",
        "#             dialect = sniffer.sniff(sample)\n",
        "#             return dialect.delimiter\n",
        "#         except csv.Error:\n",
        "#             return \"Could not determine delimiter automatically. Please inspect the file manually.\"\n",
        "\n",
        "# file_path = 'bank-full.csv'\n",
        "# delimiter = sniff_delimiter(file_path)\n",
        "# print(f\"Detected delimiter: {delimiter}\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_schema():\n",
        "    return StructType([\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"job\", StringType(), True),\n",
        "    StructField(\"marital\", StringType(), True),\n",
        "    StructField(\"education\", StringType(), True),\n",
        "    StructField(\"default\", StringType(), True),\n",
        "    StructField(\"balance\", DoubleType(), True),\n",
        "    StructField(\"housing\", StringType(), True),\n",
        "    StructField(\"loan\", StringType(), True),\n",
        "    StructField(\"contact\", StringType(), True),\n",
        "    StructField(\"day\", IntegerType(), True),\n",
        "    StructField(\"month\", StringType(), True),\n",
        "    StructField(\"duration\", IntegerType(), True),\n",
        "    StructField(\"campaign\", IntegerType(), True),\n",
        "    StructField(\"pdays\", IntegerType(), True),\n",
        "    StructField(\"previous\", IntegerType(), True),\n",
        "    StructField(\"poutcome\", StringType(), True),\n",
        "    StructField(\"y\", StringType(), True)\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "nVyGDU_XvuWL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset and print schema\n",
        "def create_spark_session(executor_cores=\"1\", max_cores=\"2\", executor_memory=\"1g\"):\n",
        "    return SparkSession.builder \\\n",
        "        .appName(\"Assignment2_ch24m571\") \\\n",
        "        .config(\"spark.executor.cores\", executor_cores) \\\n",
        "        .config(\"spark.cores.max\", max_cores) \\\n",
        "        .config(\"spark.executor.memory\", executor_memory) \\\n",
        "        .config(\"spark.driver.memory\", \"2g\") \\\n",
        "        .getOrCreate()\n",
        "# spark_c = SparkSession.builder \\\n",
        "#     .appName(\"Assignment2\") \\\n",
        "#     .config(\"spark.executor.cores\",\"2\") \\\n",
        "#     .config(\"spark.executor.memory\", \"1g\") \\\n",
        "#     .config(\"spark.driver.memory\", \"2g\") \\\n",
        "#     .getOrCreate()\n",
        "\n",
        "# data = spark_c.read.csv(\"bank-full.csv\", header=True, schema=customSchema, sep=';')\n",
        "# data.printSchema()"
      ],
      "metadata": {
        "id": "KPvlnTRUglYj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data.show()"
      ],
      "metadata": {
        "id": "On-X6aVQui-a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Use your favorite strategy to balance the dataset, if you find that data is imbalanced\n",
        "and is important to balance the dataset before training the model. Provide\n",
        "explanation of your decision. '''\n",
        "\n",
        "def apply_class_weights(spark,train_df):\n",
        "  ''' Calculate and apply class weights based on the inverse of class frequencies.\n",
        "  '''\n",
        "  try:\n",
        "    # Calculate class counts\n",
        "    train_counts = train_df.groupBy(\"y\").count().collect()\n",
        "    yes_count = [row['count'] for row in train_counts if row['y'] == 'yes'][0]\n",
        "    no_count = [row['count'] for row in train_counts if row['y'] == 'no'][0]\n",
        "    total_train_count = train_df.count()\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_weight_no = total_train_count / (2 * no_count)\n",
        "    class_weight_yes = total_train_count / (2 * yes_count)\n",
        "\n",
        "    print(f\"Calculated class weight for 'no': {class_weight_no:.4f}\")\n",
        "    print(f\"Calculated class weight for 'yes': {class_weight_yes:.4f}\")\n",
        "\n",
        "    # Map class labels to weights and add 'classWeight' column\n",
        "    mapping_expr = create_map(lit(\"no\"), lit(class_weight_no), lit(\"yes\"), lit(class_weight_yes))\n",
        "    train_df_with_weights = train_df.withColumn(\"classWeight\", mapping_expr.getItem(col(\"y\")))\n",
        "\n",
        "    print(\"Class weights applied to the training DataFrame.\")\n",
        "    return train_df_with_weights, True\n",
        "  except Exception as e:\n",
        "    print(f\"Error applying class weights: {str(e)}\")\n",
        "    return train_df, False"
      ],
      "metadata": {
        "id": "md1XzcnV5xOs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def problem_1_eda(spark , data_path ):\n",
        "  ''' Question 1 '''\n",
        "  print(\"**********************************************\")\n",
        "  # 1. Load dataset and print schema\n",
        "  print(\"1. Loading dataset and printing schema:\")\n",
        "\n",
        "  customSchema = get_schema()\n",
        "  data = spark.read.csv(data_path, header=True, schema=customSchema, sep=';')\n",
        "  data.printSchema()\n",
        "\n",
        "  # 1a. Check and remove rows with null 'y' values\n",
        "  print(\"\\n1a. Checking for and removing rows with null 'y' values:\")\n",
        "  initial_count = data.count()\n",
        "  data = data.na.drop(subset=[\"y\"])\n",
        "  rows_removed = initial_count - data.count()\n",
        "  print(f\"Initial row count: {initial_count}\")\n",
        "  print(f\"Rows removed due to null 'y': {rows_removed}\")\n",
        "  print(f\"Row count after removing null 'y': {data.count()}\")\n",
        "\n",
        "\n",
        "  # 2. Count subscriptions\n",
        "  print(\"\\n2. Subscription counts:\")\n",
        "  subscription_counts = data.groupBy(\"y\").count().orderBy(\"y\")\n",
        "  subscription_counts.show()\n",
        "\n",
        "\n",
        "\n",
        "  # 3. Print distinct values for job and education\n",
        "  print(\"\\n3. Distinct values and counts for 'job':\")\n",
        "  data.groupBy(\"job\").count().orderBy(\"count\", ascending=False).show(truncate=False)\n",
        "\n",
        "  print(\"Distinct values and counts for 'education':\")\n",
        "  data.groupBy(\"education\").count().orderBy(\"count\", ascending=False).show(truncate=False)\n",
        "\n",
        "\n",
        "\n",
        "  # 4. Split data and report distribution\n",
        "  print(\"\\n4. Splitting data into train and test sets:\")\n",
        "  train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "  print(f\"Training set size: {train_df.count()}\")\n",
        "  print(f\"Test set size: {test_df.count()}\")\n",
        "\n",
        "  print(\"\\nDistribution in training set:\")\n",
        "  train_df.groupBy(\"y\").count().orderBy(\"y\").show()\n",
        "\n",
        "  print(\"Distribution in test set:\")\n",
        "  test_df.groupBy(\"y\").count().orderBy(\"y\").show()\n",
        "\n",
        "\n",
        "\n",
        "  # 5. Check class imbalance and calculate class weights\n",
        "  print(\"\\n5. Class imbalance analysis and class weight calculation:\")\n",
        "  train_counts = train_df.groupBy(\"y\").count().collect()\n",
        "  yes_count = [row['count'] for row in train_counts if row['y'] == 'yes'][0]\n",
        "  no_count = [row['count'] for row in train_counts if row['y'] == 'no'][0]\n",
        "\n",
        "  total_train_count = train_df.count()\n",
        "  class_weight_no = total_train_count / (2 * no_count)\n",
        "  class_weight_yes = total_train_count / (2 * yes_count)\n",
        "\n",
        "  print(f\"Imbalance ratio (no/yes): {no_count / yes_count:.2f}\")\n",
        "  print(f\"Class weight for 'no': {class_weight_no:.4f}\")\n",
        "  print(f\"Class weight for 'yes': {class_weight_yes:.4f}\")\n",
        "\n",
        "  # Map class labels to weights\n",
        "  mapping_expr = create_map(lit(\"no\"), lit(class_weight_no), lit(\"yes\"), lit(class_weight_yes))\n",
        "  train_df_with_weights = train_df.withColumn(\"classWeight\", mapping_expr.getItem(col(\"y\")))\n",
        "\n",
        "  return data, train_df_with_weights, test_df"
      ],
      "metadata": {
        "id": "Z336rkcsuBka"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0eW1Thf6021N"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # spark to pandas df\n",
        "# subscription_counts_pd = subscription_counts.toPandas()\n",
        "\n",
        "# # pie chart\n",
        "# plt.figure(figsize=(6, 6))\n",
        "# plt.pie(subscription_counts_pd['count'], labels=subscription_counts_pd['y'], autopct='%1.1f%%', startangle=140)\n",
        "# plt.title('Distribution of Subscriptions (y)')\n",
        "# plt.axis('equal')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "tB-i8r_lytFY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97879cca"
      },
      "source": [
        "# # Print the distinct values of job and education and count of each value\n",
        "\n",
        "# print(\"Distinct values and counts for 'job':\")\n",
        "# data.groupBy(\"job\").count().show(truncate=False)\n",
        "\n",
        "# print(\"Distinct values and counts for 'education':\")\n",
        "# data.groupBy(\"education\").count().show(truncate=False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data in train and test dataset and report distribution of output values in train and test dataset\n",
        "\n",
        "# train_df, test_df = data.randomSplit([.8, .2], seed=42)\n",
        "# print(f\"\"\" {train_df.count()} rows -> training set | {test_df.count()} -> test set\"\"\")"
      ],
      "metadata": {
        "id": "tMMp_al7z8si"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_counts = train_df.groupBy(\"y\").count().collect()\n",
        "# yes_count = [row['count'] for row in train_counts if row['y'] == 'yes'][0]\n",
        "# no_count = [row['count'] for row in train_counts if row['y'] == 'no'][0]\n",
        "# imbalance_ratio = no_count / yes_count\n",
        "# print(f\"Imbalance ratio (no/yes): {imbalance_ratio:.2f}\")"
      ],
      "metadata": {
        "id": "pTBRiVD0YtP2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is heavily imbalanced , hence need to balance"
      ],
      "metadata": {
        "id": "2r6OvdabXzjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially used smoteenc but since the server doesnot allow additional packages to be install , cant install imbalanced-learn , hence going with class weights"
      ],
      "metadata": {
        "id": "B6hF1fkflgnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply_smoteenc_balancing(spark_c,train_df)\n",
        "# This cell is no longer needed as class weights are applied in problem_1_eda"
      ],
      "metadata": {
        "id": "VR66IfDbc2s1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2--------------"
      ],
      "metadata": {
        "id": "9bMLZGXpghuE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2607e97"
      },
      "source": [
        "# # Identify categorical and numerical columns.\n",
        "\n",
        "# numerical_columns = [col for col in train_df.columns if isinstance(train_df.schema[col].dataType,DoubleType) or isinstance(train_df.schema[col].dataType,IntegerType)]\n",
        "\n",
        "# categorical_columns = [col for col in train_df.columns if isinstance(train_df.schema[col].dataType,StringType)]\n",
        "\n",
        "# print(\"Numerical columns:\", numerical_columns)\n",
        "# print(\"Categorical columns:\", categorical_columns)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use StringIndexer and OneHotEncoder on all categorical features.\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "def problem_2_data_preprocessing(train_df, test_df):\n",
        "    \"\"\"Problem 2: Data Preprocessing\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PROBLEM 2: DATA PREPROCESSING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "    numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "\n",
        "    indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", handleInvalid=\"keep\")\n",
        "                    for col in categorical_columns]\n",
        "\n",
        "    encoders = [OneHotEncoder(inputCol=f\"{col}_indexed\", outputCol=f\"{col}_encoded\")\n",
        "                    for col in categorical_columns]\n",
        "\n",
        "\n",
        "    # Assemble all features using VectorAssembler.\n",
        "\n",
        "    feature_cols = numerical_columns + [f\"{col}_encoded\" for col in categorical_columns]\n",
        "    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "\n",
        "    # Use StringIndexer on the label column y.\n",
        "    label_indexer = StringIndexer(inputCol=\"y\", outputCol=\"label\")\n",
        "\n",
        "    return indexers, encoders, assembler, label_indexer, feature_cols\n"
      ],
      "metadata": {
        "id": "5o2u6tu1BApq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3"
      ],
      "metadata": {
        "id": "jKdZmENtChAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Problem 3: Model Building (Marks : 10)\n",
        "1. Build a pipeline using Logistic Regression.\n",
        "2. Train a random forest.\n",
        "3. Evaluate using accuracy, precision, and recall.\n",
        "4. Print the name of the best model and show confusion matrix for the best model.\n",
        "'''\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "def problem_3_model_building(train_df, test_df, indexers, encoders, assembler, label_indexer):\n",
        "  # 1. LR model\n",
        "\n",
        "  lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", weightCol=\"classWeight\")\n",
        "  lr_pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer, lr])\n",
        "\n",
        "  print(\"Training Logistic Regression model...\")\n",
        "\n",
        "  start_time = time.time()\n",
        "  lr_model = lr_pipeline.fit(train_df)\n",
        "  lr_train_time = time.time() - start_time\n",
        "  print(f\"Logistic Regression training time: {lr_train_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "  # 2. Random Forest\n",
        "  rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", weightCol=\"classWeight\",\n",
        "                              numTrees=10, seed=42)\n",
        "  rf_pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer, rf])\n",
        "\n",
        "  print(\"Training Random Forest model...\")\n",
        "  start_time = time.time()\n",
        "  rf_model = rf_pipeline.fit(train_df)\n",
        "  rf_train_time = time.time() - start_time\n",
        "  print(f\"Random Forest training time: {rf_train_time:.2f} seconds\")\n",
        "\n",
        "  # 3. Evaluate models\n",
        "  print(\"\\n3. Model Evaluation:\")\n",
        "\n",
        "  # Predictions\n",
        "  lr_predictions = lr_model.transform(test_df)\n",
        "  rf_predictions = rf_model.transform(test_df)\n",
        "\n",
        "  # Evaluators\n",
        "  accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
        "                                                        metricName=\"accuracy\")\n",
        "  precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
        "                                                          metricName=\"weightedPrecision\")\n",
        "  recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
        "                                                      metricName=\"weightedRecall\")\n",
        "\n",
        "  # Calculate metrics\n",
        "  models_metrics = {}\n",
        "\n",
        "  for name, predictions in [(\"Logistic Regression\", lr_predictions), (\"Random Forest\", rf_predictions)]:\n",
        "      accuracy = accuracy_evaluator.evaluate(predictions)\n",
        "      precision = precision_evaluator.evaluate(predictions)\n",
        "      recall = recall_evaluator.evaluate(predictions)\n",
        "\n",
        "      models_metrics[name] = {\n",
        "          'accuracy': accuracy,\n",
        "          'precision': precision,\n",
        "          'recall': recall\n",
        "      }\n",
        "\n",
        "      print(f\"\\n{name} Metrics:\")\n",
        "      print(f\"Accuracy: {accuracy:.4f}\")\n",
        "      print(f\"Precision: {precision:.4f}\")\n",
        "      print(f\"Recall: {recall:.4f}\")\n",
        "  # 4. Find best model and show confusion matrix\n",
        "  best_model_name = max(models_metrics.keys(), key=lambda x: models_metrics[x]['accuracy'])\n",
        "  print(f\"\\nBest model: {best_model_name}\")\n",
        "\n",
        "  best_predictions = lr_predictions if best_model_name == \"Logistic Regression\" else rf_predictions\n",
        "\n",
        "  # Confusion Matrix\n",
        "  print(f\"\\nConfusion Matrix for {best_model_name}:\")\n",
        "  predictionAndLabels = best_predictions.select(\"prediction\", \"label\").rdd.map(lambda x: (float(x[0]), float(x[1])))\n",
        "  metrics = MulticlassMetrics(predictionAndLabels)\n",
        "  confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "  print(confusion_matrix)\n",
        "\n",
        "  return lr_model, rf_model, models_metrics, best_model_name"
      ],
      "metadata": {
        "id": "7C-XS0h9CgwL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4 : Hyper parameter tuning"
      ],
      "metadata": {
        "id": "WOgXP6uskXVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Problem 4: Hyperparameter tuning and parallelism (Marks : 10)\n",
        "      1. Select hyperparameters for tuning and their values and justify your selection\n",
        "      2. Perform cross validation for random forest.\n",
        "\n",
        "      3. Compare the accuracy results of logistic regression, random forest without hyper-\n",
        "      parameter tuning, random forest with hyperparameter tuning models.\n",
        "'''\n",
        "\n",
        "def problem_4_hyperparameter_tuning(train_df, test_df, indexers, encoders, assembler, label_indexer, models_metrics):\n",
        "    \"\"\"Problem 4: Hyperparameter Tuning and Parallelism\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PROBLEM 4: HYPERPARAMETER TUNING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1. Select hyperparameters for Random Forest\n",
        "    print(\"1. Hyperparameter selection for Random Forest:\")\n",
        "    print(\"Selected hyperparameters:\")\n",
        "    print(\"- numTrees: Controls the number of trees in the forest (more trees = better performance but slower)\")\n",
        "    print(\"- maxDepth: Controls overfitting (deeper trees can overfit)\")\n",
        "    print(\"- minInstancesPerNode: Prevents overfitting by requiring minimum samples per leaf\")\n",
        "\n",
        "    rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", weightCol=\"classWeight\", seed=42)\n",
        "    rf_pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer, rf])\n",
        "\n",
        "    # Parameter grid\n",
        "    paramGrid = ParamGridBuilder() \\\n",
        "        .addGrid(rf.numTrees, [10, 20]) \\\n",
        "        .addGrid(rf.maxDepth, [5, 10]) \\\n",
        "        .addGrid(rf.minInstancesPerNode, [5, 10]) \\\n",
        "        .build()\n",
        "\n",
        "    # 2. Cross validation\n",
        "    print(f\"\\n2. Performing cross-validation with {len(paramGrid)} parameter combinations and reduced folds...\")\n",
        "\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
        "                                                 metricName=\"accuracy\")\n",
        "\n",
        "    crossval = CrossValidator(estimator=rf_pipeline,\n",
        "                             estimatorParamMaps=paramGrid,\n",
        "                             evaluator=evaluator,\n",
        "                             numFolds=2, # Reduced from 3 to 2\n",
        "                             seed=42)\n",
        "\n",
        "    start_time = time.time()\n",
        "    cv_model = crossval.fit(train_df)\n",
        "    cv_train_time = time.time() - start_time\n",
        "    print(f\"Cross-validation training time: {cv_train_time:.2f} seconds\")\n",
        "\n",
        "    # Best model evaluation\n",
        "    best_rf_predictions = cv_model.transform(test_df)\n",
        "    best_rf_accuracy = evaluator.evaluate(best_rf_predictions)\n",
        "\n",
        "    # 3. Compare accuracies\n",
        "    print(\"\\n3. Accuracy Comparison:\")\n",
        "    print(f\"Logistic Regression: {models_metrics['Logistic Regression']['accuracy']:.4f}\")\n",
        "    print(f\"Random Forest (no tuning): {models_metrics['Random Forest']['accuracy']:.4f}\")\n",
        "    print(f\"Random Forest (with hyperparameter tuning): {best_rf_accuracy:.4f}\")\n",
        "\n",
        "    return cv_model, best_rf_accuracy"
      ],
      "metadata": {
        "id": "XpmYrZFshOSW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def problem_5_performance_profiling():\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PROBLEM 5: PERFORMANCE PROFILING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    configurations = [\n",
        "        {\"executor_cores\": \"1\", \"max_cores\": \"2\", \"executor_memory\": \"1g\", \"parallelism\": None},\n",
        "        {\"executor_cores\": \"2\", \"max_cores\": \"2\", \"executor_memory\": \"1g\", \"parallelism\": None},\n",
        "        {\"executor_cores\": \"2\", \"max_cores\": \"2\", \"executor_memory\": \"1g\", \"parallelism\": \"1\"},\n",
        "        {\"executor_cores\": \"2\", \"max_cores\": \"2\", \"executor_memory\": \"1g\", \"parallelism\": \"2\"}\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, config in enumerate(configurations):\n",
        "        print(f\"\\nConfiguration {i+1}: {config}\")\n",
        "        spark = create_spark_session(config[\"executor_cores\"], config[\"max_cores\"], config[\"executor_memory\"])\n",
        "\n",
        "        if config[\"parallelism\"]:\n",
        "            spark.conf.set(\"spark.sql.adaptive.coalescePartitions.parallelismFirst\", \"true\")\n",
        "            spark.conf.set(\"spark.default.parallelism\", config[\"parallelism\"])\n",
        "\n",
        "        times = {}\n",
        "        config_label = f\"Cores: {config['executor_cores']}, Max: {config['max_cores']}, Mem: {config['executor_memory']}\"\n",
        "        if config['parallelism']:\n",
        "            config_label += f\", Parallelism: {config['parallelism']}\"\n",
        "        config_results = {'Configuration': config_label}\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            data_path = \"bank-full.csv\"\n",
        "            schema = get_schema()\n",
        "            data = spark.read.csv(data_path, header=True, schema=schema, sep=';')\n",
        "            train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)\n",
        "            times['Data Loading'] = time.time() - start_time\n",
        "        except Exception as e:\n",
        "            config_results['Data Loading Error'] = str(e)\n",
        "            spark.stop()\n",
        "            results.append(config_results)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "            numerical_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "\n",
        "            indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", handleInvalid=\"keep\") for col in categorical_cols]\n",
        "            encoders = [OneHotEncoder(inputCol=f\"{col}_indexed\", outputCol=f\"{col}_encoded\") for col in categorical_cols]\n",
        "\n",
        "            feature_cols = numerical_cols + [f\"{col}_encoded\" for col in categorical_cols]\n",
        "\n",
        "            assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "            label_indexer = StringIndexer(inputCol=\"y\", outputCol=\"label\")\n",
        "\n",
        "            pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer])\n",
        "            preproc_model = pipeline.fit(train_df)\n",
        "            train_df_processed = preproc_model.transform(train_df)\n",
        "            test_df_processed = preproc_model.transform(test_df)\n",
        "            times['Preprocessing'] = time.time() - start_time\n",
        "        except Exception as e:\n",
        "            config_results['Preprocessing Error'] = str(e)\n",
        "            spark.stop()\n",
        "            results.append(config_results)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=10, seed=42)\n",
        "            model = rf.fit(train_df_processed)\n",
        "            times['Model Training'] = time.time() - start_time\n",
        "        except Exception as e:\n",
        "            config_results['Model Training Error'] = str(e)\n",
        "            spark.stop()\n",
        "            results.append(config_results)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            predictions = model.transform(test_df_processed)\n",
        "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "            accuracy = evaluator.evaluate(predictions)\n",
        "            times['Model Evaluation'] = time.time() - start_time\n",
        "            times['Accuracy'] = accuracy\n",
        "        except Exception as e:\n",
        "            config_results['Model Evaluation Error'] = str(e)\n",
        "            spark.stop()\n",
        "            results.append(config_results)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # FIX: Use Python's built-in sum\n",
        "            total_time = 0.0\n",
        "            for k, v in times.items():\n",
        "                if k != 'Accuracy' and isinstance(v, (int, float)):\n",
        "                    total_time += v\n",
        "            times['Total Time'] = total_time\n",
        "            config_results.update(times)\n",
        "        except Exception as e:\n",
        "            config_results['Total Time Calculation Error'] = str(e)\n",
        "\n",
        "        results.append(config_results)\n",
        "        spark.stop()\n",
        "\n",
        "    # Convert to Pandas DataFrame for better table printing\n",
        "    df_results = pd.DataFrame(results)\n",
        "    print(\"\\n=== Performance Results Table ===\")\n",
        "    print(df_results.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "TEwZh9YJRLEr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAIN FUNCTION OF CODE"
      ],
      "metadata": {
        "id": "QoGS5dR8s2nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  ''' Main'''\n",
        "# Initialize Spark session\n",
        "  spark = create_spark_session()\n",
        "  try:\n",
        "    data_path = 'bank-full.csv'\n",
        "\n",
        "    # Problem 1: Data Understanding\n",
        "    data, train_df, test_df = problem_1_eda(spark, data_path)\n",
        "\n",
        "    # Problem 2: Data Preprocessing\n",
        "    indexers, encoders, assembler, label_indexer, feature_cols = problem_2_data_preprocessing(train_df, test_df)\n",
        "\n",
        "    # Problem 3: Model Building\n",
        "    lr_model, rf_model, models_metrics, best_model_name = problem_3_model_building(\n",
        "        train_df, test_df, indexers, encoders, assembler, label_indexer)\n",
        "\n",
        "    # Problem 4: Hyperparameter Tuning\n",
        "    cv_model, best_rf_accuracy = problem_4_hyperparameter_tuning(\n",
        "        train_df, test_df, indexers, encoders, assembler, label_indexer, models_metrics)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error in main execution: {str(e)}\")\n",
        "\n",
        "  finally:\n",
        "    spark.stop()"
      ],
      "metadata": {
        "id": "bb-mG9Lts1_2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Soxq5woP7Lll",
        "outputId": "9baf2617-b8fe-4e55-d6ad-e78086edd6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********************************************\n",
            "1. Loading dataset and printing schema:\n",
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- balance: double (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- day: integer (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- campaign: integer (nullable = true)\n",
            " |-- pdays: integer (nullable = true)\n",
            " |-- previous: integer (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- y: string (nullable = true)\n",
            "\n",
            "\n",
            "1a. Checking for and removing rows with null 'y' values:\n",
            "Initial row count: 45211\n",
            "Rows removed due to null 'y': 0\n",
            "Row count after removing null 'y': 45211\n",
            "\n",
            "2. Subscription counts:\n",
            "+---+-----+\n",
            "|  y|count|\n",
            "+---+-----+\n",
            "| no|39922|\n",
            "|yes| 5289|\n",
            "+---+-----+\n",
            "\n",
            "\n",
            "3. Distinct values and counts for 'job':\n",
            "+-------------+-----+\n",
            "|job          |count|\n",
            "+-------------+-----+\n",
            "|blue-collar  |9732 |\n",
            "|management   |9458 |\n",
            "|technician   |7597 |\n",
            "|admin.       |5171 |\n",
            "|services     |4154 |\n",
            "|retired      |2264 |\n",
            "|self-employed|1579 |\n",
            "|entrepreneur |1487 |\n",
            "|unemployed   |1303 |\n",
            "|housemaid    |1240 |\n",
            "|student      |938  |\n",
            "|unknown      |288  |\n",
            "+-------------+-----+\n",
            "\n",
            "Distinct values and counts for 'education':\n",
            "+---------+-----+\n",
            "|education|count|\n",
            "+---------+-----+\n",
            "|secondary|23202|\n",
            "|tertiary |13301|\n",
            "|primary  |6851 |\n",
            "|unknown  |1857 |\n",
            "+---------+-----+\n",
            "\n",
            "\n",
            "4. Splitting data into train and test sets:\n",
            "Training set size: 36180\n",
            "Test set size: 9031\n",
            "\n",
            "Distribution in training set:\n",
            "+---+-----+\n",
            "|  y|count|\n",
            "+---+-----+\n",
            "| no|31899|\n",
            "|yes| 4281|\n",
            "+---+-----+\n",
            "\n",
            "Distribution in test set:\n",
            "+---+-----+\n",
            "|  y|count|\n",
            "+---+-----+\n",
            "| no| 8023|\n",
            "|yes| 1008|\n",
            "+---+-----+\n",
            "\n",
            "\n",
            "5. Class imbalance analysis and class weight calculation:\n",
            "Imbalance ratio (no/yes): 7.45\n",
            "Class weight for 'no': 0.5671\n",
            "Class weight for 'yes': 4.2256\n",
            "\n",
            "============================================================\n",
            "PROBLEM 2: DATA PREPROCESSING\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyspark/sql/column.py:460: FutureWarning: A column as 'key' in getItem is deprecated as of Spark 3.0, and will not be supported in the future release. Use `column[key]` or `column.key` syntax instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression model...\n",
            "Logistic Regression training time: 30.96 seconds\n",
            "Training Random Forest model...\n",
            "Random Forest training time: 22.63 seconds\n",
            "\n",
            "3. Model Evaluation:\n",
            "\n",
            "Logistic Regression Metrics:\n",
            "Accuracy: 0.8463\n",
            "Precision: 0.9120\n",
            "Recall: 0.8463\n",
            "\n",
            "Random Forest Metrics:\n",
            "Accuracy: 0.8150\n",
            "Precision: 0.9079\n",
            "Recall: 0.8150\n",
            "\n",
            "Best model: Logistic Regression\n",
            "\n",
            "Confusion Matrix for Logistic Regression:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6807. 1216.]\n",
            " [ 172.  836.]]\n",
            "\n",
            "============================================================\n",
            "PROBLEM 4: HYPERPARAMETER TUNING\n",
            "============================================================\n",
            "1. Hyperparameter selection for Random Forest:\n",
            "Selected hyperparameters:\n",
            "- numTrees: Controls the number of trees in the forest (more trees = better performance but slower)\n",
            "- maxDepth: Controls overfitting (deeper trees can overfit)\n",
            "- minInstancesPerNode: Prevents overfitting by requiring minimum samples per leaf\n",
            "\n",
            "2. Performing cross-validation with 27 parameter combinations...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "problem_5_performance_profiling()"
      ],
      "metadata": {
        "id": "0plOT7GFKJUr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}