{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUX70Jo0IVQS7w7H/GFLnB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymuos/masters-practise-repo/blob/main/TERM3/AI_at_Scale/Assignments/Assignment2/Assignment2U.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cBC68pZCaSow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2da28bd-dc4e-4e46-b26c-81b2cefc575d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark pandas imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the Bank Marketing dataset (saved in drive) to build a binary\n",
        "classifier that predicts whether a customer will subscribe to a term deposit\n",
        "using Spark MLlib.\n",
        "\n",
        "\n",
        "Do the following tasks on the dataset:\n",
        "\n",
        "\n",
        "Problem 1 : Data Understanding (Marks : 10)"
      ],
      "metadata": {
        "id": "W7fzCKr8sYSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import regexp_replace, col, countDistinct, col, sum\n",
        "from pyspark.sql.functions import count, when, lit, create_map\n",
        "from pyspark.sql.types import StringType, DoubleType, IntegerType ,StructType,StructField\n",
        "from pyspark.ml.feature import Imputer, VectorAssembler,StandardScaler\n",
        "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
        "import time\n",
        "from pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor\n",
        "from pyspark.ml import PipelineModel"
      ],
      "metadata": {
        "id": "98UUQTdqtgxG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e3829ee",
        "outputId": "d9e1d944-878f-4588-ef16-0ad5e1d8aec7"
      },
      "source": [
        "import csv\n",
        "\n",
        "def sniff_delimiter(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        # Read a sample of the file\n",
        "        sample = f.read(4096)\n",
        "        # Use the sniffer to guess the delimiter\n",
        "        sniffer = csv.Sniffer()\n",
        "        try:\n",
        "            dialect = sniffer.sniff(sample)\n",
        "            return dialect.delimiter\n",
        "        except csv.Error:\n",
        "            return \"Could not determine delimiter automatically. Please inspect the file manually.\"\n",
        "\n",
        "file_path = 'bank-full.csv'\n",
        "delimiter = sniff_delimiter(file_path)\n",
        "print(f\"Detected delimiter: {delimiter}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected delimiter: ;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_schema():\n",
        "    return StructType([\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"job\", StringType(), True),\n",
        "    StructField(\"marital\", StringType(), True),\n",
        "    StructField(\"education\", StringType(), True),\n",
        "    StructField(\"default\", StringType(), True),\n",
        "    StructField(\"balance\", DoubleType(), True),\n",
        "    StructField(\"housing\", StringType(), True),\n",
        "    StructField(\"loan\", StringType(), True),\n",
        "    StructField(\"contact\", StringType(), True),\n",
        "    StructField(\"day\", IntegerType(), True),\n",
        "    StructField(\"month\", StringType(), True),\n",
        "    StructField(\"duration\", IntegerType(), True),\n",
        "    StructField(\"campaign\", IntegerType(), True),\n",
        "    StructField(\"pdays\", IntegerType(), True),\n",
        "    StructField(\"previous\", IntegerType(), True),\n",
        "    StructField(\"poutcome\", StringType(), True),\n",
        "    StructField(\"y\", StringType(), True)\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "nVyGDU_XvuWL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset and print schema\n",
        "def create_spark_session(executor_cores=\"1\", max_cores=\"2\", executor_memory=\"1g\"):\n",
        "    return SparkSession.builder \\\n",
        "        .appName(\"Assignment2_ch24m571\") \\\n",
        "        .config(\"spark.executor.cores\", executor_cores) \\\n",
        "        .config(\"spark.cores.max\", max_cores) \\\n",
        "        .config(\"spark.executor.memory\", executor_memory) \\\n",
        "        .config(\"spark.driver.memory\", \"2g\") \\\n",
        "        .getOrCreate()\n",
        "# spark_c = SparkSession.builder \\\n",
        "#     .appName(\"Assignment2\") \\\n",
        "#     .config(\"spark.executor.cores\",\"2\") \\\n",
        "#     .config(\"spark.executor.memory\", \"1g\") \\\n",
        "#     .config(\"spark.driver.memory\", \"2g\") \\\n",
        "#     .getOrCreate()\n",
        "\n",
        "# data = spark_c.read.csv(\"bank-full.csv\", header=True, schema=customSchema, sep=';')\n",
        "# data.printSchema()"
      ],
      "metadata": {
        "id": "KPvlnTRUglYj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data.show()"
      ],
      "metadata": {
        "id": "On-X6aVQui-a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Use your favorite strategy to balance the dataset, if you find that data is imbalanced\n",
        "and is important to balance the dataset before training the model. Provide\n",
        "explanation of your decision. '''\n",
        "\n",
        "def apply_smoteenc_balancing(spark,train_df):\n",
        "  ''' since smoteenc works on pandas dataframe , we shall convert to pandas and work\n",
        "  '''\n",
        "  from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "  try:\n",
        "    # Convert Spark DataFrame to Pandas DataFrame\n",
        "    pandas_df = train_df.toPandas()\n",
        "\n",
        "    # feature and target split\n",
        "\n",
        "    feature_cols = [col for col in pandas_df.columns if col != 'y']\n",
        "    X = pandas_df[feature_cols]\n",
        "    y = pandas_df['y']\n",
        "\n",
        "  # Identify categorical columns for SMOTENC\n",
        "    categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "    categorical_indices = [X.columns.get_loc(col) for col in categorical_cols if col in X.columns]\n",
        "\n",
        "    print(f\"Categorical column indices for SMOTENC: {categorical_indices}\")\n",
        "    # Apply SMOTENC\n",
        "    smoteenc = SMOTENC(categorical_features=categorical_indices, random_state=42)\n",
        "    X_resampled, y_resampled = smoteenc.fit_resample(X, y)\n",
        "\n",
        "    # Create resampled DataFrame\n",
        "    resampled_df = X_resampled.copy()\n",
        "    resampled_df['y'] = y_resampled\n",
        "\n",
        "    print(f\"Original dataset size: {len(pandas_df)}\")\n",
        "    print(f\"Resampled dataset size: {len(resampled_df)}\")\n",
        "    print(\"Class distribution after SMOTEENC:\")\n",
        "    print(resampled_df['y'].value_counts())\n",
        "\n",
        "    resampled_spark_df = spark.createDataFrame(resampled_df)\n",
        "    return resampled_spark_df, True\n",
        "  except Exception as e:\n",
        "    print(f\"Error applying SMOTENC: {str(e)}\")\n",
        "    return train_df, False\n",
        "\n"
      ],
      "metadata": {
        "id": "md1XzcnV5xOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def problem_1_eda(spark , data_path ):\n",
        "  ''' Question 1 '''\n",
        "  print(\"**********************************************\")\n",
        "# 1. Load dataset and print schema\n",
        "  print(\"1. Loading dataset and printing schema:\")\n",
        "\n",
        "  customSchema = get_schema()\n",
        "  data = spark.read.csv(data_path, header=True, schema=customSchema, sep=';')\n",
        "  data.printSchema()\n",
        "\n",
        "  # 2. Count subscriptions\n",
        "  print(\"\\n2. Subscription counts:\")\n",
        "  subscription_counts = data.groupBy(\"y\").count().orderBy(\"y\")\n",
        "  subscription_counts.show()\n",
        "\n",
        "\n",
        "\n",
        "  # 3. Print distinct values for job and education\n",
        "  print(\"\\n3. Distinct values and counts for 'job':\")\n",
        "  data.groupBy(\"job\").count().orderBy(\"count\", ascending=False).show(truncate=False)\n",
        "\n",
        "  print(\"Distinct values and counts for 'education':\")\n",
        "  data.groupBy(\"education\").count().orderBy(\"count\", ascending=False).show(truncate=False)\n",
        "\n",
        "\n",
        "\n",
        "  # 4. Split data and report distribution\n",
        "  print(\"\\n4. Splitting data into train and test sets:\")\n",
        "  train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "  print(f\"Training set size: {train_df.count()}\")\n",
        "  print(f\"Test set size: {test_df.count()}\")\n",
        "\n",
        "  print(\"\\nDistribution in training set:\")\n",
        "  train_df.groupBy(\"y\").count().orderBy(\"y\").show()\n",
        "\n",
        "  print(\"Distribution in test set:\")\n",
        "  test_df.groupBy(\"y\").count().orderBy(\"y\").show()\n",
        "\n",
        "\n",
        "\n",
        "  # 5. Check class imbalance and balance if needed\n",
        "  print(\"\\n5. Class imbalance analysis:\")\n",
        "  train_counts = train_df.groupBy(\"y\").count().collect()\n",
        "  yes_count = [row['count'] for row in train_counts if row['y'] == 'yes'][0]\n",
        "  no_count = [row['count'] for row in train_counts if row['y'] == 'no'][0]\n",
        "\n",
        "  imbalance_ratio = no_count / yes_count\n",
        "  print(f\"Imbalance ratio (no/yes): {imbalance_ratio:.2f}\")\n",
        "\n",
        "  balanced_train_df, smote_success = apply_smoteenc_balancing(spark, train_df)\n",
        "  if smote_success:\n",
        "      train_df = balanced_train_df.withColumn(\"classWeight\", lit(1.0))\n",
        "      # adds a classWeight column with a default value of 1.0 to balanced training data.\n",
        "      # It ensures all samples, whether original or synthetic, are equally weighted for model training after SMOTENC oversampling.\n",
        "      return data, train_df, test_df\n",
        "\n"
      ],
      "metadata": {
        "id": "Z336rkcsuBka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0eW1Thf6021N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # spark to pandas df\n",
        "# subscription_counts_pd = subscription_counts.toPandas()\n",
        "\n",
        "# # pie chart\n",
        "# plt.figure(figsize=(6, 6))\n",
        "# plt.pie(subscription_counts_pd['count'], labels=subscription_counts_pd['y'], autopct='%1.1f%%', startangle=140)\n",
        "# plt.title('Distribution of Subscriptions (y)')\n",
        "# plt.axis('equal')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "tB-i8r_lytFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97879cca"
      },
      "source": [
        "# # Print the distinct values of job and education and count of each value\n",
        "\n",
        "# print(\"Distinct values and counts for 'job':\")\n",
        "# data.groupBy(\"job\").count().show(truncate=False)\n",
        "\n",
        "# print(\"Distinct values and counts for 'education':\")\n",
        "# data.groupBy(\"education\").count().show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data in train and test dataset and report distribution of output values in train and test dataset\n",
        "\n",
        "# train_df, test_df = data.randomSplit([.8, .2], seed=42)\n",
        "# print(f\"\"\" {train_df.count()} rows -> training set | {test_df.count()} -> test set\"\"\")"
      ],
      "metadata": {
        "id": "tMMp_al7z8si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_counts = train_df.groupBy(\"y\").count().collect()\n",
        "# yes_count = [row['count'] for row in train_counts if row['y'] == 'yes'][0]\n",
        "# no_count = [row['count'] for row in train_counts if row['y'] == 'no'][0]\n",
        "# imbalance_ratio = no_count / yes_count\n",
        "# print(f\"Imbalance ratio (no/yes): {imbalance_ratio:.2f}\")"
      ],
      "metadata": {
        "id": "pTBRiVD0YtP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is heavily imbalanced , hence need to balance"
      ],
      "metadata": {
        "id": "2r6OvdabXzjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apply_smoteenc_balancing(spark_c,train_df)"
      ],
      "metadata": {
        "id": "VR66IfDbc2s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reasoning for applying SMOTENC as balancing strategy\n",
        "- for numerical categories it applies normal SMOTE\n",
        "- for categorical items it applies most frequent occurence from its neighouring values\n",
        "- this is applied to training data only\n",
        "- ideally this could be hyperparameter tuned"
      ],
      "metadata": {
        "id": "ZNmyB5LKeJ_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2--------------"
      ],
      "metadata": {
        "id": "9bMLZGXpghuE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2607e97"
      },
      "source": [
        "# Identify categorical and numerical columns.\n",
        "\n",
        "numerical_columns = [col for col in train_df.columns if isinstance(train_df.schema[col].dataType,DoubleType) or isinstance(train_df.schema[col].dataType,IntegerType)]\n",
        "\n",
        "categorical_columns = [col for col in train_df.columns if isinstance(train_df.schema[col].dataType,StringType)]\n",
        "\n",
        "print(\"Numerical columns:\", numerical_columns)\n",
        "print(\"Categorical columns:\", categorical_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use StringIndexer and OneHotEncoder on all categorical features.\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "def problem_2_data_preprocessing(train_df, test_df):\n",
        "    \"\"\"Problem 2: Data Preprocessing\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PROBLEM 2: DATA PREPROCESSING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "    numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "\n",
        "    indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", handleInvalid=\"keep\")\n",
        "                    for col in categorical_columns]\n",
        "\n",
        "    encoders = [OneHotEncoder(inputCol=f\"{col}_indexed\", outputCol=f\"{col}_encoded\")\n",
        "                    for col in categorical_columns]\n",
        "\n",
        "\n",
        "    # Assemble all features using VectorAssembler.\n",
        "\n",
        "    feature_cols = numerical_columns + [f\"{col}_encoded\" for col in categorical_columns]\n",
        "    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "\n",
        "    # Use StringIndexer on the label column y.\n",
        "    label_indexer = StringIndexer(inputCol=\"y\", outputCol=\"label\")\n",
        "\n",
        "    return indexers, encoders, assembler, label_indexer, feature_cols\n"
      ],
      "metadata": {
        "id": "5o2u6tu1BApq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3"
      ],
      "metadata": {
        "id": "jKdZmENtChAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Problem 3: Model Building (Marks : 10)\n",
        "1. Build a pipeline using Logistic Regression.\n",
        "2. Train a random forest.\n",
        "3. Evaluate using accuracy, precision, and recall.\n",
        "4. Print the name of the best model and show confusion matrix for the best model.\n",
        "'''\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "def problem_3_model_building(train_df, test_df, indexers, encoders, assembler, label_indexer):\n",
        "  # 1. LR model\n",
        "\n",
        "  lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", weightCol=\"classWeight\")\n",
        "  lr_pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer, lr])\n",
        "\n",
        "  print(\"Training Logistic Regression model...\")\n",
        "\n",
        "  start_time = time.time()\n",
        "  lr_model = lr_pipeline.fit(train_df)\n",
        "  lr_train_time = time.time() - start_time\n",
        "  print(f\"Logistic Regression training time: {lr_train_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "  # 2. Random Forest\n",
        "  rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", weightCol=\"classWeight\",\n",
        "                              numTrees=10, seed=42)\n",
        "  rf_pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer, rf])\n",
        "\n",
        "  print(\"Training Random Forest model...\")\n",
        "  start_time = time.time()\n",
        "  rf_model = rf_pipeline.fit(train_df)\n",
        "  rf_train_time = time.time() - start_time\n",
        "  print(f\"Random Forest training time: {rf_train_time:.2f} seconds\")\n",
        "\n",
        "  # 3. Evaluate models\n",
        "  print(\"\\n3. Model Evaluation:\")\n",
        "\n",
        "  # Predictions\n",
        "  lr_predictions = lr_model.transform(test_df)\n",
        "  rf_predictions = rf_model.transform(test_df)\n",
        "\n",
        "  # Evaluators\n",
        "  accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
        "                                                        metricName=\"accuracy\")\n",
        "  precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
        "                                                          metricName=\"weightedPrecision\")\n",
        "  recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
        "                                                      metricName=\"weightedRecall\")\n",
        "\n",
        "  # Calculate metrics\n",
        "  models_metrics = {}\n",
        "\n",
        "  for name, predictions in [(\"Logistic Regression\", lr_predictions), (\"Random Forest\", rf_predictions)]:\n",
        "      accuracy = accuracy_evaluator.evaluate(predictions)\n",
        "      precision = precision_evaluator.evaluate(predictions)\n",
        "      recall = recall_evaluator.evaluate(predictions)\n",
        "\n",
        "      models_metrics[name] = {\n",
        "          'accuracy': accuracy,\n",
        "          'precision': precision,\n",
        "          'recall': recall\n",
        "      }\n",
        "\n",
        "      print(f\"\\n{name} Metrics:\")\n",
        "      print(f\"Accuracy: {accuracy:.4f}\")\n",
        "      print(f\"Precision: {precision:.4f}\")\n",
        "      print(f\"Recall: {recall:.4f}\")\n",
        "  # 4. Find best model and show confusion matrix\n",
        "  best_model_name = max(models_metrics.keys(), key=lambda x: models_metrics[x]['accuracy'])\n",
        "  print(f\"\\nBest model: {best_model_name}\")\n",
        "\n",
        "  best_predictions = lr_predictions if best_model_name == \"Logistic Regression\" else rf_predictions\n",
        "\n",
        "  # Confusion Matrix\n",
        "  print(f\"\\nConfusion Matrix for {best_model_name}:\")\n",
        "  predictionAndLabels = best_predictions.select(\"prediction\", \"label\").rdd.map(lambda x: (float(x[0]), float(x[1])))\n",
        "  metrics = MulticlassMetrics(predictionAndLabels)\n",
        "  confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "  print(confusion_matrix)\n",
        "\n",
        "  return lr_model, rf_model, models_metrics, best_model_name"
      ],
      "metadata": {
        "id": "7C-XS0h9CgwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4 : Hyper parameter tuning"
      ],
      "metadata": {
        "id": "WOgXP6uskXVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Problem 4: Hyperparameter tuning and parallelism (Marks : 10)\n",
        "      1. Select hyperparameters for tuning and their values and justify your selection\n",
        "      2. Perform cross validation for random forest.\n",
        "\n",
        "      3. Compare the accuracy results of logistic regression, random forest without hyper-\n",
        "      parameter tuning, random forest with hyperparameter tuning models.\n",
        "'''\n",
        "\n",
        "def problem_4_hyperparameter_tuning(train_df, test_df, indexers, encoders, assembler, label_indexer, models_metrics):\n",
        "    \"\"\"Problem 4: Hyperparameter Tuning and Parallelism\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PROBLEM 4: HYPERPARAMETER TUNING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1. Select hyperparameters for Random Forest\n",
        "    print(\"1. Hyperparameter selection for Random Forest:\")\n",
        "    print(\"Selected hyperparameters:\")\n",
        "    print(\"- numTrees: Controls the number of trees in the forest (more trees = better performance but slower)\")\n",
        "    print(\"- maxDepth: Controls overfitting (deeper trees can overfit)\")\n",
        "    print(\"- minInstancesPerNode: Prevents overfitting by requiring minimum samples per leaf\")\n",
        "\n",
        "    rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", weightCol=\"classWeight\", seed=42)\n",
        "    rf_pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer, rf])\n",
        "\n",
        "    # Parameter grid\n",
        "    paramGrid = ParamGridBuilder() \\\n",
        "        .addGrid(rf.numTrees, [10, 20, 30]) \\\n",
        "        .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
        "        .addGrid(rf.minInstancesPerNode, [1, 5, 10]) \\\n",
        "        .build()\n",
        "\n",
        "    # 2. Cross validation\n",
        "    print(f\"\\n2. Performing cross-validation with {len(paramGrid)} parameter combinations...\")\n",
        "\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
        "                                                 metricName=\"accuracy\")\n",
        "\n",
        "    crossval = CrossValidator(estimator=rf_pipeline,\n",
        "                             estimatorParamMaps=paramGrid,\n",
        "                             evaluator=evaluator,\n",
        "                             numFolds=3,\n",
        "                             seed=42)\n",
        "\n",
        "    start_time = time.time()\n",
        "    cv_model = crossval.fit(train_df)\n",
        "    cv_train_time = time.time() - start_time\n",
        "    print(f\"Cross-validation training time: {cv_train_time:.2f} seconds\")\n",
        "\n",
        "    # Best model evaluation\n",
        "    best_rf_predictions = cv_model.transform(test_df)\n",
        "    best_rf_accuracy = evaluator.evaluate(best_rf_predictions)\n",
        "\n",
        "    # 3. Compare accuracies\n",
        "    print(\"\\n3. Accuracy Comparison:\")\n",
        "    print(f\"Logistic Regression: {models_metrics['Logistic Regression']['accuracy']:.4f}\")\n",
        "    print(f\"Random Forest (no tuning): {models_metrics['Random Forest']['accuracy']:.4f}\")\n",
        "    print(f\"Random Forest (with hyperparameter tuning): {best_rf_accuracy:.4f}\")\n",
        "\n",
        "    return cv_model, best_rf_accuracy"
      ],
      "metadata": {
        "id": "XpmYrZFshOSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def problem_5_performance_profiling():\n",
        "    \"\"\"Problem 5: Performance Profiling\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PROBLEM 5: PERFORMANCE PROFILING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    from pyspark.sql.functions import col, count, sum as spark_sum, when, lit, create_map\n",
        "\n",
        "    configurations = [\n",
        "        {\"executor_cores\": \"1\", \"max_cores\": \"2\", \"executor_memory\": \"1g\", \"parallelism\": None},\n",
        "        {\"executor_cores\": \"2\", \"max_cores\": \"2\", \"executor_memory\": \"1g\", \"parallelism\": None},\n",
        "        {\"executor_cores\": \"2\", \"max_cores\": \"2\", \"executor_memory\": \"1g\", \"parallelism\": \"1\"},\n",
        "        {\"executor_cores\": \"2\", \"max_cores\": \"2\", \"executor_memory\": \"1g\", \"parallelism\": \"2\"}\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, config in enumerate(configurations):\n",
        "        print(f\"\\nConfiguration {i+1}: {config}\")\n",
        "\n",
        "        # Create new Spark session with specific configuration\n",
        "        spark = create_spark_session(config[\"executor_cores\"], config[\"max_cores\"], config[\"executor_memory\"])\n",
        "\n",
        "        if config[\"parallelism\"]:\n",
        "            spark.conf.set(\"spark.sql.adaptive.coalescePartitions.parallelismFirst\", \"true\")\n",
        "            spark.conf.set(\"spark.default.parallelism\", config[\"parallelism\"])\n",
        "\n",
        "        try:\n",
        "            # Time each section\n",
        "            times = {}\n",
        "\n",
        "            # Data loading\n",
        "            start_time = time.time()\n",
        "            data_path = \"bank-full.csv\"  # TODO: Update this path for server\n",
        "            customSchema = get_schema()\n",
        "            data = spark.read.csv(data_path, header=True, schema=customSchema, sep=';')\n",
        "            train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)\n",
        "            times['Data Loading'] = time.time() - start_time\n",
        "\n",
        "            # Preprocessing\n",
        "            start_time = time.time()\n",
        "            categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "            numerical_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "\n",
        "            indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", handleInvalid=\"keep\")\n",
        "                       for col in categorical_cols]\n",
        "            encoders = [OneHotEncoder(inputCol=f\"{col}_indexed\", outputCol=f\"{col}_encoded\")\n",
        "                       for col in categorical_cols]\n",
        "            feature_cols = numerical_cols + [f\"{col}_encoded\" for col in categorical_cols]\n",
        "            assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "            label_indexer = StringIndexer(inputCol=\"y\", outputCol=\"label\")\n",
        "            times['Preprocessing'] = time.time() - start_time\n",
        "\n",
        "            # Model training\n",
        "            start_time = time.time()\n",
        "            train_df = train_df.withColumn(\"classWeight\", lit(1.0))  # Simplified for timing\n",
        "            rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=10, seed=42)\n",
        "            pipeline = Pipeline(stages=indexers + encoders + [assembler, label_indexer, rf])\n",
        "            model = pipeline.fit(train_df)\n",
        "            times['Model Training'] = time.time() - start_time\n",
        "\n",
        "            # Model evaluation\n",
        "            start_time = time.time()\n",
        "            predictions = model.transform(test_df)\n",
        "            accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
        "                                                       metricName=\"accuracy\").evaluate(predictions)\n",
        "            times['Model Evaluation'] = time.time() - start_time\n",
        "\n",
        "            total_time = sum(times.values())\n",
        "            times['Total'] = total_time\n",
        "\n",
        "            results.append({\n",
        "                'Configuration': f\"Cores: {config['executor_cores']}, Max: {config['max_cores']}, \" +\n",
        "                               f\"Memory: {config['executor_memory']}\" +\n",
        "                               (f\", Parallelism: {config['parallelism']}\" if config['parallelism'] else \"\"),\n",
        "                **times\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in configuration {i+1}: {str(e)}\")\n",
        "            results.append({\n",
        "                'Configuration': f\"Cores: {config['executor_cores']}, Max: {config['max_cores']}, \" +\n",
        "                               f\"Memory: {config['executor_memory']}\" +\n",
        "                               (f\", Parallelism: {config['parallelism']}\" if config['parallelism'] else \"\"),\n",
        "                'Error': str(e)\n",
        "            })\n",
        "\n",
        "        finally:\n",
        "            spark.stop()"
      ],
      "metadata": {
        "id": "asbZWUJVkpG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAIN FUNCTION OF CODE"
      ],
      "metadata": {
        "id": "QoGS5dR8s2nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  ''' Main'''\n",
        "# Initialize Spark session\n",
        "  spark = create_spark_session()\n",
        "  try:\n",
        "    data_path = 'bank-full.csv'\n",
        "\n",
        "    # Problem 1: Data Understanding\n",
        "    data, train_df, test_df = problem_1_eda(spark, data_path)\n",
        "\n",
        "    # Problem 2: Data Preprocessing\n",
        "    indexers, encoders, assembler, label_indexer, feature_cols = problem_2_data_preprocessing(train_df, test_df)\n",
        "\n",
        "    # Problem 3: Model Building\n",
        "    lr_model, rf_model, models_metrics, best_model_name = problem_3_model_building(\n",
        "        train_df, test_df, indexers, encoders, assembler, label_indexer)\n",
        "\n",
        "    # Problem 4: Hyperparameter Tuning\n",
        "    cv_model, best_rf_accuracy = problem_4_hyperparameter_tuning(\n",
        "        train_df, test_df, indexers, encoders, assembler, label_indexer, models_metrics)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error in main execution: {str(e)}\")\n",
        "\n",
        "  finally:\n",
        "    spark.stop()"
      ],
      "metadata": {
        "id": "bb-mG9Lts1_2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "Soxq5woP7Lll",
        "outputId": "51fac8b1-3aa2-44ae-ef39-5e72e2ba7cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in main execution: name 'problem_1_eda' is not defined\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'spark' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-451043146.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-9-2203420472.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
          ]
        }
      ]
    }
  ]
}