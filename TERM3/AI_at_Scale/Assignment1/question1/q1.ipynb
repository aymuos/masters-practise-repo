{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymuos/masters-practise-repo/blob/main/TERM3/AI_at_Scale/Assignment1/question1/q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a1c8746",
      "metadata": {
        "id": "4a1c8746"
      },
      "source": [
        "q1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ad9a1a3b",
      "metadata": {
        "id": "ad9a1a3b"
      },
      "outputs": [],
      "source": [
        "! pip install -q pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6281940f",
      "metadata": {
        "id": "6281940f"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "from pyspark.sql.functions import col, sum\n",
        "\n",
        "base_path = f'./'\n",
        "\n",
        "#base_path = f\"/opt/spark/data/{student_id}/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "eebe58c7",
      "metadata": {
        "id": "eebe58c7"
      },
      "outputs": [],
      "source": [
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"assignment1_CH24M571\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.executor.memory\", \"512m\") \\\n",
        "    .config(\"spark.executor.core\", \"4\") \\\n",
        "    .config(\"spark.driver.memory\", \"2g\") \\\n",
        "    .config(\"spark.executor.instances\", \"2\")\\\n",
        "    .config(\"spark.driver.core\", \"2\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"INFO\")\n",
        "\n",
        "\n",
        "# # spark = SparkSession.builder \\: This starts the process of building a SparkSession.\n",
        "# .appName(\"Assignment1\") \\: This sets the name of the Spark application to \"Assignment1\".\n",
        "# .master(\"local[*]\") \\: This configures Spark to run locally on your machine using all available cores.\n",
        "# .config(\"spark.executor.memory\", \"512m\") \\: This sets the amount of memory allocated to each executor (the processes that perform the actual computations) to 512 megabytes.\n",
        "# .config(\"spark.executor.core\", \"4\") \\: This sets the number of cores used by each executor to 4.\n",
        "# .config(\"spark.driver.memory\", \"2g\") \\: This sets the amount of memory allocated to the Spark driver (the process that coordinates the execution) to 2 gigabytes.\n",
        "# .config(\"spark.executor.instances\", \"2\")\\: This sets the number of executor instances to 2.\n",
        "# .config(\"spark.driver.core\", \"2\") \\: This sets the number of cores used by the driver to 2.\n",
        "# .getOrCreate(): This retrieves an existing SparkSession if one is already running, or creates a new one if not.\n",
        "# spark.sparkContext.setLogLevel(\"INFO\"): This sets the logging level for the Spark context to \"INFO\", which means informational messages will be displayed."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the schemas for the 3 csv s\n",
        "\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, ArrayType, StructType\n",
        "\n",
        "# Customers schema\n",
        "customers_schema = StructType([\n",
        "    StructField(\"customer_id\", StringType(), nullable=False),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"email\", StringType(), True),\n",
        "    StructField(\"preferences\", StringType(), True),  # Will parse to ArrayType later\n",
        "    StructField(\"address\", StringType(), True)       # Will parse to StructType later\n",
        "])\n",
        "\n",
        "# Orders schema\n",
        "orders_schema = StructType([\n",
        "    StructField(\"order_id\", StringType(), nullable=False),\n",
        "    StructField(\"customer_id\", StringType(), True),\n",
        "    StructField(\"order_date\", StringType(), True),\n",
        "    StructField(\"items\", StringType(), True),\n",
        "    StructField(\"shipping_address\", StringType(), True),\n",
        "    StructField(\"total_amount\", FloatType(), True)\n",
        "])\n",
        "\n",
        "# Products schema\n",
        "products_schema = StructType([\n",
        "    StructField(\"product_id\", StringType(), nullable=False),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"category\", StringType(), True),\n",
        "    StructField(\"price\", FloatType(), True),\n",
        "    StructField(\"tags\", StringType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "PTt_JyaGcAdg"
      },
      "id": "PTt_JyaGcAdg",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining file paths\n",
        "\n",
        "customers_csv= base_path +'customers.csv'\n",
        "orders_csv = base_path +'orders.csv'\n",
        "products_csv = base_path +'products.csv'"
      ],
      "metadata": {
        "id": "yAH4Stp9loA8"
      },
      "id": "yAH4Stp9loA8",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "6f6cf714",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f6cf714",
        "outputId": "4e1e958e-cdd4-4fea-dd98-eb7813989e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---+--------------------+--------------------+--------------------+\n",
            "|customer_id|       name|age|               email|         preferences|             address|\n",
            "+-----------+-----------+---+--------------------+--------------------+--------------------+\n",
            "| CUST000001| Customer_1| 61|customer1@example...|[\"sports\", \"trave...|{\"street\": \"2796 ...|\n",
            "| CUST000002| Customer_2| 55|customer2@example...|                NULL|{\"street\": \"5409 ...|\n",
            "| CUST000003| Customer_3| 79|customer3@example...|[\"movies\", \"books...|{\"street\": \"6081 ...|\n",
            "| CUST000004| Customer_4| 73|customer4@example...|[\"books\", \"fitnes...|{\"street\": \"3303 ...|\n",
            "| CUST000005| Customer_5| 80|customer5@example...|[\"music\", \"books\"...|{\"street\": \"4864 ...|\n",
            "| CUST000006| Customer_6| 44|customer6@example...|[\"travel\", \"fitne...|{\"street\": \"3592 ...|\n",
            "| CUST000007| Customer_7| 57|customer7@example...|[\"music\", \"movies...|{\"street\": \"2932 ...|\n",
            "| CUST000008| Customer_8| 20|                NULL|[\"books\", \"fitnes...|{\"street\": \"8148 ...|\n",
            "| CUST000009| Customer_9| 57|customer9@example...|         [\"fitness\"]|{\"street\": \"375 M...|\n",
            "| CUST000010|Customer_10| 29|customer10@exampl...| [\"travel\", \"books\"]|{\"street\": \"7677 ...|\n",
            "| CUST000011|Customer_11| 39|customer11@exampl...|          [\"travel\"]|{\"street\": \"813 M...|\n",
            "| CUST000012|Customer_12| 22|customer12@exampl...|          [\"sports\"]|{\"street\": \"9355 ...|\n",
            "| CUST000013|Customer_13| 38|customer13example...|          [\"movies\"]|{\"street\": \"5511 ...|\n",
            "| CUST000014|Customer_14| 47|customer14@exampl...|[\"fitness\", \"book...|{\"street\": \"1411 ...|\n",
            "| CUST000015|Customer_15| 80|customer15@exampl...|                NULL|{\"street\": \"8376 ...|\n",
            "| CUST000016|Customer_16| 70|customer16@exampl...|[\"travel\", \"movies\"]|{\"street\": \"2764 ...|\n",
            "| CUST000017|Customer_17| 18|customer17@exampl...|           [\"books\"]|{\"street\": \"1329 ...|\n",
            "| CUST000018|Customer_18| 80|customer18@exampl...| [\"music\", \"sports\"]|{\"street\": \"3926 ...|\n",
            "| CUST000019|Customer_19| 58|customer19@exampl...|  [\"music\", \"books\"]|{\"street\": \"4571 ...|\n",
            "| CUST000020|Customer_20| 75|customer20@exampl...|[\"fitness\", \"book...|{\"street\": \"9780 ...|\n",
            "+-----------+-----------+---+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# read csv file\n",
        "customers_df = spark.read.csv(customers_csv, header=True, schema=customers_schema,escape=\"\\\"\",quote=\"\\\"\")\n",
        "# show the dataframe\n",
        "customers_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read csv file\n",
        "orders_df = spark.read.csv(orders_csv,header=True, schema=orders_schema,escape=\"\\\"\",quote=\"\\\"\")\n",
        "# show the dataframe\n",
        "orders_df.show()"
      ],
      "metadata": {
        "id": "3fVEm05GQjy7",
        "outputId": "29ad1b9f-479c-4b7f-9265-eb869e838336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3fVEm05GQjy7",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+----------+--------------------+--------------------+------------+\n",
            "|  order_id|customer_id|order_date|               items|    shipping_address|total_amount|\n",
            "+----------+-----------+----------+--------------------+--------------------+------------+\n",
            "|ORD0000001| CUST000046|2023-08-16|[{\"product_id\": \"...|{\"street\": \"703 M...|     1112.73|\n",
            "|ORD0000002| CUST000027|2023-11-20|[{\"product_id\": \"...|{\"street\": \"6503 ...|      456.04|\n",
            "|ORD0000003| CUST000093|2023-11-27|[{\"product_id\": \"...|{\"street\": \"9664 ...|     1420.89|\n",
            "|ORD0000004| CUST000017|2023-04-08|[{\"product_id\": \"...|{\"street\": \"1329 ...|     1450.66|\n",
            "|ORD0000005| CUST000092|2023-09-24|[{\"product_id\": \"...|{\"street\": \"3075 ...|     2016.47|\n",
            "|ORD0000006| CUST000029|2023-09-04|[{\"product_id\": \"...|{\"street\": \"176 M...|      800.88|\n",
            "|ORD0000007| CUST000093|2023-10-22|[{\"product_id\": \"...|{\"street\": \"9664 ...|        NULL|\n",
            "|ORD0000008| CUST000094|2023-10-20|[{\"product_id\": \"...|{\"street\": \"4391 ...|      121.35|\n",
            "|ORD0000009| CUST000094|2023-01-22|[{\"product_id\": \"...|                NULL|     1112.73|\n",
            "|ORD0000010| CUST000042|2023-05-18|[{\"product_id\": \"...|{\"street\": \"6033 ...|     1609.02|\n",
            "|ORD0000011| CUST000035|2023-10-29|[{\"product_id\": \"...|{\"street\": \"3299 ...|      192.89|\n",
            "|ORD0000012| CUST000084|2023-02-04|[{\"product_id\": \"...|{\"street\": \"3490 ...|      1071.3|\n",
            "|ORD0000013| CUST000068|2023-08-27|[{\"product_id\": \"...|{\"street\": \"1228 ...|      973.79|\n",
            "|ORD0000014| CUST000033|2023-11-25|[{\"product_id\": \"...|{\"street\": \"7338 ...|      712.38|\n",
            "|ORD0000015| CUST000041|2023-12-13|[{\"product_id\": \"...|{\"street\": \"4560 ...|     1326.85|\n",
            "|ORD0000016| CUST000087|2023-03-24|[{\"product_id\": \"...|{\"street\": \"6819 ...|       448.0|\n",
            "|ORD0000017| CUST000050|2023-10-09|[{\"product_id\": \"...|{\"street\": \"337 M...|      800.88|\n",
            "|ORD0000018| CUST000078|2023-10-27|[{\"product_id\": \"...|{\"street\": \"8458 ...|      363.04|\n",
            "|ORD0000019| CUST000075|2023-11-09|[{\"product_id\": \"...|{\"street\": \"1783 ...|     1660.92|\n",
            "|ORD0000020| CUST000003|2023-05-20|[{\"product_id\": \"...|{\"street\": \"6081 ...|     1518.71|\n",
            "+----------+-----------+----------+--------------------+--------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read csv file\n",
        "products_df = spark.read.csv(products_csv, header=True, schema=products_schema,escape=\"\\\"\",quote=\"\\\"\")\n",
        "# show the dataframe\n",
        "products_df.show()"
      ],
      "metadata": {
        "id": "CueZzkyWQkil",
        "outputId": "d7aa9d39-87b7-4747-c9aa-a627095d495a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CueZzkyWQkil",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+-----------+------+--------------------+\n",
            "|product_id|      name|   category| price|                tags|\n",
            "+----------+----------+-----------+------+--------------------+\n",
            "| PROD00001| Product_1|electronics|  5.32|[\"new\", \"sale\", \"...|\n",
            "| PROD00002| Product_2|     sports| 59.11|[\"limited\", \"eco-...|\n",
            "| PROD00003| Product_3|     sports|370.91|             [\"new\"]|\n",
            "| PROD00004| Product_4|     sports| 69.84|            [\"sale\"]|\n",
            "| PROD00005| Product_5|     sports| 135.9|[\"sale\", \"new\", \"...|\n",
            "| PROD00006| Product_6|electronics|428.33|[\"new\", \"limited\"...|\n",
            "| PROD00007| Product_7|electronics|400.44|         [\"popular\"]|\n",
            "| PROD00008| Product_8|     sports| 40.45|[\"limited\", \"popu...|\n",
            "| PROD00009| Product_9|     sports|187.57|[\"limited\", \"new\"...|\n",
            "| PROD00010|Product_10|  furniture| 176.2|  [\"popular\", \"new\"]|\n",
            "+----------+----------+-----------+------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Print the size of each dataframe and schema"
      ],
      "metadata": {
        "id": "mgenbkYXr2ye"
      },
      "id": "mgenbkYXr2ye"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Rows: {customers_df.count()}\")\n",
        "print(f\"Columns: {len(customers_df.columns)}\")\n",
        "customers_df.printSchema()\n",
        "print(\"-------------------------------------\")\n",
        "print(f\"Rows: {orders_df.count()}\")\n",
        "print(f\"Columns: {len(orders_df.columns)}\")\n",
        "orders_df.printSchema()\n",
        "print(\"-------------------------------------\")\n",
        "print(f\"Rows: {products_df.count()}\")\n",
        "print(f\"Columns: {len(products_df.columns)}\")\n",
        "products_df.printSchema()\n",
        "print(\"-------------------------------------\")"
      ],
      "metadata": {
        "id": "lN_bszONRci5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827bf0f0-d59a-4dff-b914-26a1436a50e9"
      },
      "id": "lN_bszONRci5",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 100\n",
            "Columns: 6\n",
            "root\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- email: string (nullable = true)\n",
            " |-- preferences: string (nullable = true)\n",
            " |-- address: string (nullable = true)\n",
            "\n",
            "-------------------------------------\n",
            "Rows: 500\n",
            "Columns: 6\n",
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- order_date: string (nullable = true)\n",
            " |-- items: string (nullable = true)\n",
            " |-- shipping_address: string (nullable = true)\n",
            " |-- total_amount: float (nullable = true)\n",
            "\n",
            "-------------------------------------\n",
            "Rows: 10\n",
            "Columns: 5\n",
            "root\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- price: float (nullable = true)\n",
            " |-- tags: string (nullable = true)\n",
            "\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-\n",
        "Identify the corrupt values in each file and report the number of corrupt rows and\n",
        "total corrupt values in each file."
      ],
      "metadata": {
        "id": "FSfHYBtVwbBd"
      },
      "id": "FSfHYBtVwbBd"
    },
    {
      "cell_type": "code",
      "source": [
        "# null check\n",
        "\n",
        "from pyspark"
      ],
      "metadata": {
        "id": "qEeE-t8WwjZa"
      },
      "id": "qEeE-t8WwjZa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95fa8627"
      },
      "source": [
        "## Identify null values\n",
        "\n",
        "### Subtask:\n",
        "Check for null values in columns that are expected to be non-nullable (like the ID columns).\n"
      ],
      "id": "95fa8627"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30a46b95"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary functions and check for null values in the ID columns of each DataFrame as instructed.\n",
        "\n"
      ],
      "id": "30a46b95"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee80454e",
        "outputId": "2c378f78-457d-4002-b096-260c5430df8e"
      },
      "source": [
        "# Check for null values in customers_df\n",
        "\n",
        "# CHECKING JUST THE IDS - IDEALLY THERE SHOULDNT BE NONE\n",
        "\n",
        "customers_null_counts = customers_df.select(\n",
        "    sum(col(\"customer_id\")\n",
        "    .isNull()         # check if each value in column is null , if so cast the value as 0 or 1\n",
        "    .cast(\"integer\"))\n",
        "    .alias(\"customer_id_nulls\")).collect()[0]  # aggregate and put into a new column\n",
        "\n",
        "    #\n",
        "print(f\"Customers DataFrame - Nulls in customer_id: {customers_null_counts['customer_id_nulls']}\")\n",
        "\n",
        "# Check for null values in orders_df\n",
        "\n",
        "orders_null_counts = orders_df.select(\n",
        "    sum(col(\"order_id\").isNull().cast(\"integer\")).alias(\"order_id_nulls\"),\n",
        "    sum(col(\"customer_id\").isNull().cast(\"integer\")).alias(\"customer_id_nulls\")\n",
        ").collect()[0]\n",
        "\n",
        "print(f\"Orders DataFrame - Nulls in order_id: {orders_null_counts['order_id_nulls']}\")\n",
        "print(f\"Orders DataFrame - Nulls in customer_id: {orders_null_counts['customer_id_nulls']}\")\n",
        "\n",
        "\n",
        "# Check for null values in products_df\n",
        "products_null_counts = products_df.select(sum(col(\"product_id\").isNull().cast(\"integer\")).alias(\"product_id_nulls\")).collect()[0]\n",
        "print(f\"Products DataFrame - Nulls in product_id: {products_null_counts['product_id_nulls']}\")"
      ],
      "id": "ee80454e",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers DataFrame - Nulls in customer_id: 0\n",
            "Orders DataFrame - Nulls in order_id: 0\n",
            "Orders DataFrame - Nulls in customer_id: 0\n",
            "Products DataFrame - Nulls in product_id: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8666d5c",
        "outputId": "46adbb8f-be5b-446b-9415-aee0bb0902f1"
      },
      "source": [
        "\n",
        "# Check for null values in all columns of customers_df\n",
        "\n",
        "print(\"Null counts for customers_df:\")\n",
        "\n",
        "customers_df.agg(*(sum(col(c).isNull().cast(\"integer\")).alias(c) for c in customers_df.columns)).show()\n",
        "\n",
        "# loop over all columns and check for null values\n",
        "\n",
        "# Check for null values in all columns of orders_df\n",
        "print(\"Null counts for orders_df:\")\n",
        "orders_df.agg(*(sum(col(c).isNull().cast(\"integer\")).alias(c) for c in orders_df.columns)).show()\n",
        "\n",
        "# Check for null values in all columns of products_df\n",
        "print(\"Null counts for products_df:\")\n",
        "products_df.agg(*(sum(col(c).isNull().cast(\"integer\")).alias(c) for c in products_df.columns)).show()"
      ],
      "id": "d8666d5c",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null counts for customers_df:\n",
            "+-----------+----+---+-----+-----------+-------+\n",
            "|customer_id|name|age|email|preferences|address|\n",
            "+-----------+----+---+-----+-----------+-------+\n",
            "|          0|   0|  1|    5|          5|      0|\n",
            "+-----------+----+---+-----+-----------+-------+\n",
            "\n",
            "Null counts for orders_df:\n",
            "+--------+-----------+----------+-----+----------------+------------+\n",
            "|order_id|customer_id|order_date|items|shipping_address|total_amount|\n",
            "+--------+-----------+----------+-----+----------------+------------+\n",
            "|       0|          0|         0|    0|              23|          14|\n",
            "+--------+-----------+----------+-----+----------------+------------+\n",
            "\n",
            "Null counts for products_df:\n",
            "+----------+----+--------+-----+----+\n",
            "|product_id|name|category|price|tags|\n",
            "+----------+----+--------+-----+----+\n",
            "|         0|   0|       0|    0|   0|\n",
            "+----------+----+--------+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For numerical columns, fill the missing values with mean value"
      ],
      "metadata": {
        "id": "uVj68QGV82hQ"
      },
      "id": "uVj68QGV82hQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a8f1345",
        "outputId": "9e86fa5e-84e7-41f3-a9de-c39ae1b34bbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pyspark.sql.functions import mean\n",
        "\n",
        "# Calculate the mean of the 'age' column in customers_df\n",
        "mean_age = customers_df.select(mean(col(\"age\"))).collect()[0][0]\n",
        "\n",
        "# Fill null values in the 'age' column with the calculated mean\n",
        "customers_df = customers_df.na.fill(mean_age, subset=[\"age\"])\n",
        "\n",
        "# Calculate the mean of the 'total_amount' column in orders_df\n",
        "mean_total_amount = orders_df.select(mean(col(\"total_amount\"))).collect()[0][0]\n",
        "\n",
        "# Fill null values in the 'total_amount' column with the calculated mean\n",
        "orders_df = orders_df.na.fill(mean_total_amount, subset=[\"total_amount\"])\n",
        "\n",
        "print(\"Null counts for customers_df after filling 'age' nulls:\")\n",
        "customers_df.agg(*(sum(col(c).isNull().cast(\"integer\")).alias(c) for c in customers_df.columns)).show()\n",
        "\n",
        "print(\"Null counts for orders_df after filling 'total_amount' nulls:\")\n",
        "orders_df.agg(*(sum(col(c).isNull().cast(\"integer\")).alias(c) for c in orders_df.columns)).show()"
      ],
      "id": "2a8f1345",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null counts for customers_df after filling 'age' nulls:\n",
            "+-----------+----+---+-----+-----------+-------+\n",
            "|customer_id|name|age|email|preferences|address|\n",
            "+-----------+----+---+-----+-----------+-------+\n",
            "|          0|   0|  0|    5|          5|      0|\n",
            "+-----------+----+---+-----+-----------+-------+\n",
            "\n",
            "Null counts for orders_df after filling 'total_amount' nulls:\n",
            "+--------+-----------+----------+-----+----------------+------------+\n",
            "|order_id|customer_id|order_date|items|shipping_address|total_amount|\n",
            "+--------+-----------+----------+-----+----------------+------------+\n",
            "|       0|          0|         0|    0|              23|           0|\n",
            "+--------+-----------+----------+-----+----------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For categorical or string columns, fill the missing values with most frequent value."
      ],
      "metadata": {
        "id": "EusKpcST9SGC"
      },
      "id": "EusKpcST9SGC"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mode\n",
        "\n",
        "# Identify string columns in customers_df\n",
        "string_cols_customers = [c for c, t in customers_df.dtypes if t == 'string']\n",
        "\n",
        "# Fill null values in string columns of customers_df with the mode\n",
        "for col_name in string_cols_customers:\n",
        "    # Calculate the mode for the current column\n",
        "    mode_value = customers_df.groupBy(col_name).count().orderBy(\"count\", ascending=False).first()[0]\n",
        "    # Fill nulls with the mode value\n",
        "    customers_df = customers_df.na.fill(mode_value, subset=[col_name])\n",
        "\n",
        "# Identify string columns in orders_df\n",
        "string_cols_orders = [c for c, t in orders_df.dtypes if t == 'string']\n",
        "\n",
        "# Fill null values in string columns of orders_df with the mode\n",
        "for col_name in string_cols_orders:\n",
        "    # Calculate the mode for the current column\n",
        "    mode_value = orders_df.groupBy(col_name).count().orderBy(\"count\", ascending=False).first()[0]\n",
        "    # Fill nulls with the mode value\n",
        "    orders_df = orders_df.na.fill(mode_value, subset=[col_name])\n",
        "\n",
        "# Identify string columns in products_df\n",
        "string_cols_products = [c for c, t in products_df.dtypes if t == 'string']\n",
        "\n",
        "# Fill null values in string columns of products_df with the mode\n",
        "for col_name in string_cols_products:\n",
        "    # Calculate the mode for the current column\n",
        "    mode_value = products_df.groupBy(col_name).count().orderBy(\"count\", ascending=False).first()[0]\n",
        "    # Fill nulls with the mode value\n",
        "    products_df = products_df.na.fill(mode_value, subset=[col_name])\n",
        "\n",
        "\n",
        "print(\"Null counts for customers_df after filling string column nulls:\")\n",
        "customers_df.agg(*(sum(col(c).isNull().cast(\"integer\")).alias(c) for c in customers_df.columns)).show()\n",
        "\n",
        "print(\"Null counts for orders_df after filling string column nulls:\")\n",
        "orders_df.agg(*(sum(col(c).isNull().cast(\"integer\")).alias(c) for c in orders_df.columns)).show()\n",
        "\n",
        "print(\"Null counts for products_df after filling string column nulls:\")\n",
        "products_df.agg(*(sum(col(c).isNull().cast(\"integer\")).alias(c) for c in products_df.columns)).show()"
      ],
      "metadata": {
        "id": "9Y2v1ufu9QrP",
        "outputId": "700f67e3-f73b-483f-dfea-30e2478f3b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "id": "9Y2v1ufu9QrP",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PySparkTypeError",
          "evalue": "[NOT_BOOL_OR_DICT_OR_FLOAT_OR_INT_OR_STR] Argument `value` should be a bool, dict, float, int or str, got NoneType.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-56-1414601369.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmode_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustomers_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Fill nulls with the mode value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcustomers_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustomers_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Identify string columns in orders_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfill\u001b[0;34m(self, value, subset)\u001b[0m\n\u001b[1;32m   5839\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5840\u001b[0m     ) -> DataFrame:\n\u001b[0;32m-> 5841\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5843\u001b[0m     \u001b[0mfill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, subset)\u001b[0m\n\u001b[1;32m   4438\u001b[0m         \"\"\"\n\u001b[1;32m   4439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4440\u001b[0;31m             raise PySparkTypeError(\n\u001b[0m\u001b[1;32m   4441\u001b[0m                 \u001b[0merror_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NOT_BOOL_OR_DICT_OR_FLOAT_OR_INT_OR_STR\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4442\u001b[0m                 \u001b[0mmessage_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"arg_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"arg_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_BOOL_OR_DICT_OR_FLOAT_OR_INT_OR_STR] Argument `value` should be a bool, dict, float, int or str, got NoneType."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}