{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1ad2c04f",
      "metadata": {
        "id": "1ad2c04f"
      },
      "source": [
        "# PySpark ML Assignment on Clustering, Dimensionality Reduction & Imbalanced Data Handling\n",
        "\n",
        "This notebook includes questions on:\n",
        "- [Clustering](https://spark.apache.org/docs/latest/ml-clustering.html)\n",
        "   -- [KMeans Clustering](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.clustering.KMeans.html)\n",
        "- [Dimensionality Reduction (PCA)](https://spark.apache.org/docs/latest/ml-features.html#pca)\n",
        "- Handling Imbalanced Data in PySpark\n",
        "\n",
        "_Note: Depending on dataset availability or environment (e.g., SMOTE support), you might need to adapt paths or use pseudocode._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "27895842",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (5.2.0)\n",
            "Requirement already satisfied: pyspark in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (4.0.0)\n",
            "Requirement already satisfied: numpy in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (2.2.6)\n",
            "Requirement already satisfied: pandas in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (2.3.0)\n",
            "Requirement already satisfied: scikit-learn in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (1.7.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from pyspark) (0.10.9.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from beautifulsoup4->gdown) (4.14.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (2025.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/aymuos/Documents/Github/masters-practise-repo/TERM3/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install gdown pyspark numpy pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bvAraPoG7D5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "bvAraPoG7D5e",
        "outputId": "6a6bccbf-2727-4cb1-afef-9de0b080c371"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1v0TrkO0o4_UJbBlUiqpGrne7WnQSWIac\n",
            "To: /home/aymuos/Documents/Github/masters-practise-repo/TERM3/AI_at_Scale/ClassWork/data_wk7.csv\n",
            "100%|██████████| 3.88k/3.88k [00:00<00:00, 5.06MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'data_wk7.csv'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "file_id = \"1v0TrkO0o4_UJbBlUiqpGrne7WnQSWIac\"  # e.g., '1uNw9...'\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "gdown.download(url, \"data_wk7.csv\", quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "736b0f52",
      "metadata": {
        "id": "736b0f52"
      },
      "source": [
        "## Q1: Load a sample dataset and create spark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hZu3K7oo6P7z",
      "metadata": {
        "id": "hZu3K7oo6P7z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7225b465",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, FloatType , StringType\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"ImbalancedData_workings\").getOrCreate()\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"sepal_length\", FloatType(), False),\n",
        "    StructField(\"sepal_width\", FloatType(), True),\n",
        "    StructField(\"petal_length\", FloatType(), True),\n",
        "    StructField(\"petal_width\", FloatType(), True),\n",
        "    StructField(\"species\", StringType(), True),])\n",
        "# Load the dataset\n",
        "df_spark = spark.read.csv(\"data_wk7.csv\", header=True, schema=schema)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c892a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rename columns to snake_case (already in snake_case, but let's ensure consistency)\n",
        "for col_name in df_spark.columns:\n",
        "    df_spark = df_spark.withColumnRenamed(col_name, col_name.lower().replace(\" \", \"_\"))\n",
        "\n",
        "df_spark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89bce31b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c5978a77",
      "metadata": {
        "id": "c5978a77"
      },
      "source": [
        "## Q2: Assemble features into a single vector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4932833a",
      "metadata": {},
      "source": [
        "A feature transformer that merges multiple columns into a vector column --> VectorAssembler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3b7f8ea1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------------------------+-------+\n",
            "|features                                                                    |species|\n",
            "+----------------------------------------------------------------------------+-------+\n",
            "|[5.099999904632568,3.5,1.399999976158142,0.20000000298023224]               |setosa |\n",
            "|[4.900000095367432,3.0,1.399999976158142,0.20000000298023224]               |setosa |\n",
            "|[4.699999809265137,3.200000047683716,1.2999999523162842,0.20000000298023224]|setosa |\n",
            "|[4.599999904632568,3.0999999046325684,1.5,0.20000000298023224]              |setosa |\n",
            "|[5.0,3.5999999046325684,1.399999976158142,0.20000000298023224]              |setosa |\n",
            "+----------------------------------------------------------------------------+-------+\n",
            "only showing top 5 rows\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/06/25 17:03:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
            " Header: sepal length (cm), sepal width (cm), petal length (cm), petal width (cm), species\n",
            " Schema: sepal_length, sepal_width, petal_length, petal_width, species\n",
            "Expected: sepal_length but found: sepal length (cm)\n",
            "CSV file: file:///home/aymuos/Documents/Github/masters-practise-repo/TERM3/AI_at_Scale/ClassWork/data_wk7.csv\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "feature_cols = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "df_features = assembler.transform(df_spark)\n",
        "df_features.select(\"features\", \"species\").show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0a258f7",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7710a2",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3295a5c7",
      "metadata": {
        "id": "3295a5c7"
      },
      "source": [
        "## Q3: Apply KMeans Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6cd43c7",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7c58642",
      "metadata": {
        "id": "d7c58642"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b8fb6dd",
      "metadata": {
        "id": "9b8fb6dd"
      },
      "source": [
        "## Q4: Evaluate KMeans Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d23843c6",
      "metadata": {
        "id": "d23843c6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e837eecc",
      "metadata": {
        "id": "e837eecc"
      },
      "source": [
        "## Q5: Apply PCA for dimensionality reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43ef5b95",
      "metadata": {
        "id": "43ef5b95"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9d380e82",
      "metadata": {
        "id": "9d380e82"
      },
      "source": [
        "## Q6: Visualize PCA-transformed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d85f9996",
      "metadata": {
        "id": "d85f9996"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c055768b",
      "metadata": {
        "id": "c055768b"
      },
      "source": [
        "## Q7: Create an imbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9f326bd",
      "metadata": {
        "id": "f9f326bd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "79518eaa",
      "metadata": {
        "id": "79518eaa"
      },
      "source": [
        "## Q8: Use SMOTE or resampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd0bd368",
      "metadata": {
        "id": "bd0bd368"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7cddc386",
      "metadata": {
        "id": "7cddc386"
      },
      "source": [
        "## Q9: Use class weights in a classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ffcaf1",
      "metadata": {
        "id": "48ffcaf1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "84670fbd",
      "metadata": {
        "id": "84670fbd"
      },
      "source": [
        "## Q10: Evaluate classification on imbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a2e00bd",
      "metadata": {
        "id": "1a2e00bd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
