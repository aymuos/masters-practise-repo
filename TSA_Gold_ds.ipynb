{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbtNxRclW00r7nW9kodz0n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymuos/masters-practise-repo/blob/main/TSA_Gold_ds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gkh6pg4scHtR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group - 8\n",
        "CH24M548 - Mounika Chowdary Pamulapati\n",
        "\n",
        "CH24M571 - Soumya Mukherjee\n",
        "\n",
        "CH24M577 - Surya Kandala\n",
        "\n",
        "Dataset : Gold.csv\n"
      ],
      "metadata": {
        "id": "MH_pFnKPV6FH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps followed :\n",
        "1. **Importing the dataset** :\n",
        "2. **Cleaning the dataset**: Ensured that missing dates were added and forward fill of the data for the missing dates. Dropped NaN records whereever observed.\n",
        "3. **Stationartiy Check**: Validated if the timeseries is stationary or not by performing ADF and KSS test. For ADF test if p<0.05, then it says the timeseries is stationary. If p>0.05 for KSS test, it indicates the timeseries is stationary.\n",
        "\n",
        "4. **First Order Differencing & Log Differencing:** Performing first order differencing to make the timeseries stationary.\n",
        "5. **ACF and PACF:** Compute Auto Correlation and Partial correlation to understand the presence of MA and AR components.\n",
        "6. **Power Spectral Density:** For a process to be stationary, both mean and variance need to be independent of the absolute time. Hence, validating if Variance is dependent on the absolute time.\n",
        "7. **Random Walk:** Based on the ACF and PACF values, going with ARMA model of 010 since ACF and PACF results indicate complete white noise.\n",
        "8. **Akaike's Information Criteria:** Since the forecast is only a straight line, checked the AIC values for models starting from 000 till 332. Chose that model which has less AIC value\n",
        "9. **Train, Test & Generate Forecast:** Generated the forecast for 122 model which got less AIC value in step 7.\n",
        "10. **MSE, RMSE, MAPE:** Identify the Mean Square Error and Root Mean Square Error to check the residual details.\n",
        "11. **Alternate Non-Lionear models:** Since we have variance as a function of absolute time, linear models might not be the right choice to move ahead, hence trying out the non-linear models ARCH and GARCH to model the data.\n"
      ],
      "metadata": {
        "id": "neHxmAfYZjTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- Starting off by installing dependecies ---\n"
      ],
      "metadata": {
        "id": "ZlX3pNMDh3gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas seaborn matplotlib"
      ],
      "metadata": {
        "id": "KOT-MHF7h3BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dependencies"
      ],
      "metadata": {
        "id": "b-24OeLzj0B8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JK7kvoTJj30e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use winget to get the data"
      ],
      "metadata": {
        "id": "nuKR648Sj_qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the dataset\n",
        "!wget 'https://drive.google.com/uc?export=download&id=1cXGNQ3NtUERYHbP5Jm4fmZR1jmd2M9ME' -O Gold.csv"
      ],
      "metadata": {
        "id": "3fwQQRtskmNX",
        "outputId": "7da459e8-e336-4a2b-f85d-5567e39fbbc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-26 20:11:57--  https://drive.google.com/uc?export=download&id=1cXGNQ3NtUERYHbP5Jm4fmZR1jmd2M9ME\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.163.139, 142.251.163.100, 142.251.163.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.163.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1cXGNQ3NtUERYHbP5Jm4fmZR1jmd2M9ME&export=download [following]\n",
            "--2024-12-26 20:11:57--  https://drive.usercontent.google.com/download?id=1cXGNQ3NtUERYHbP5Jm4fmZR1jmd2M9ME&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.253.115.132, 2607:f8b0:4004:c06::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.253.115.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95758 (94K) [application/octet-stream]\n",
            "Saving to: ‘Gold.csv’\n",
            "\n",
            "Gold.csv            100%[===================>]  93.51K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-12-26 20:11:59 (6.45 MB/s) - ‘Gold.csv’ saved [95758/95758]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    gold_data = pd.read_csv('Gold.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'Gold.csv' not found. Please make sure the file exists and the path is correct.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "Z3iWAGAgmNRV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividing the data into test train split using scikit learn . The train_test_split() method is used to split our data into train and test sets."
      ],
      "metadata": {
        "id": "BDPhuA48nll7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "gold_data = gold_data.set_index('DATE')  # setting DATE as the index column\n",
        "\n",
        "# Divide the data into training and testing sets (80:20 split)\n",
        "train_data, test_data = train_test_split(\n",
        "        gold_data,\n",
        "        test_size=0.2,\n",
        "        shuffle=False\n",
        "        ) # shuffle=False to maintain time order\n",
        "\n",
        "# Write the training and testing sets to new CSV files, overwriting if they exist\n",
        "train_data.to_csv('training.csv', index=False) #index=False to avoid writing row indices\n",
        "test_data.to_csv('test.csv', index=False) #index=False to avoid writing row indices"
      ],
      "metadata": {
        "id": "oorrh-qQZzOp"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}