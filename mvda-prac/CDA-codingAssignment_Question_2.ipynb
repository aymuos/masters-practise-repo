{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAjZ_Hi5icLT"
      },
      "source": [
        "# Instructions for Question 2\n",
        "\n",
        "Using the provided Colab notebook and Yale Faces dataset, answer the following:\n",
        "\n",
        "1. **Dataset Overview**  \n",
        "   The Yale Faces dataset contains grayscale images of 15 subjects, each with six facial expressions. Each image has a resolution of 243 x 320 pixels.  \n",
        "   - Preprocess the dataset by converting each image into a vector of size 77760 by stacking the columns of the image.  \n",
        "   - Construct the PCA-representative image using only the first component to capture the central tendency of each subject's images.  \n",
        "\n",
        "2. **Function Implementation**  \n",
        "   Write a modular function named `predict_class` that meets the following specifications:  \n",
        "   - **Inputs**:  \n",
        "     - `image_number` (integer, 1â€“90): The number of the image to classify.  \n",
        "     - `image_data` (NumPy array, 90 x 77760): Matrix representing the image vectors.  \n",
        "     - `image_labels` (NumPy array, size 90): Labels corresponding to the image data.  \n",
        "   - **Functionality**:  \n",
        "     - Predict the subject number of the given image using the Euclidean distance between the input image vector and the PCA-representative images.  \n",
        "     - Ensure all required library imports and preprocessing steps are modularized into separate functions or methods.  \n",
        "   - **Output**:  \n",
        "     - Return the `predicted_class` (integer) as the subject number.  \n",
        "\n",
        "   Here is an example of the function signature and call:  \n",
        "\n",
        "   ```python\n",
        "   def predict_class(image_number, image_data, image_labels):\n",
        "       # image_number: integer, from 1 to 90\n",
        "       # image_data: NumPy array of shape 90 x 77760\n",
        "       # image_labels: NumPy array of size 90\n",
        "       \n",
        "       # Include calls to your modular functions here\n",
        "       \n",
        "       return predicted_class\n",
        "   ```\n",
        "\n",
        "   Example test call:  \n",
        "   ```python\n",
        "   predicted_class = predict_class(64, image_data, labels)\n",
        "   ```  \n",
        "\n",
        "   **Expected Output**:  \n",
        "   ```\n",
        "   predicted_class = 11\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "### Notebook Organization:\n",
        "\n",
        "- Ensure the notebook is **well-structured** and **modular**.\n",
        "- Include all necessary **library imports** and **helper functions** in the earlier cells of the notebook.\n",
        "- Write the final function, `predict_class(image_number, image_data, image_labels)`, in the **last cell** of the notebook.\n",
        "\n",
        "---\n",
        "\n",
        "### Submission Guidelines:\n",
        "\n",
        "- Ensure your notebook is clean, with **appropriate comments** and **well-documented code**.  \n",
        "- Verify that your function's output matches the expected values before submission.  \n",
        "- Submit the notebook as a `.ipynb` file, ensuring it runs without errors.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nIUxPRmxkne",
        "outputId": "50de69ff-12ef-43dd-809a-799ea96e843c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BI_nPOaliUyi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from scipy.spatial.distance import euclidean\n",
        "import matplotlib.image as img\n",
        "import imageio.v2 as iio\n",
        "from PIL import Image\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import rarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5g6undxmevX",
        "outputId": "52c10070-eb56-460a-e937-e9521cb0fc60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(90, 77760)\n"
          ]
        }
      ],
      "source": [
        "# Extract files\n",
        "rar_file_path = 'yalefacespng.rar'\n",
        "image_directory = 'yalefacespng'\n",
        "with rarfile.RarFile(rar_file_path) as rf:\n",
        "  rf.extractall(image_directory)\n",
        "  img_names = rf.namelist()\n",
        "  img_names = sorted(img_names) # get list of image names\n",
        "\n",
        "def preprocess_data(img_names):\n",
        "  image_data = []\n",
        "\n",
        "  for image_name in img_names:\n",
        "    img_path = os.path.join(image_directory,image_name)\n",
        "    img = Image.open(img_path).convert('L')  # Convert image to grayscale\n",
        "    img_col = np.array(img)  # Convert to numpy array\n",
        "    img_col = img_col.flatten()\n",
        "    image_data.append(img_col)\n",
        "\n",
        "  image_data = np.array(image_data)\n",
        "  print(image_data.shape)\n",
        "  image_labels = [file.split('.')[0] for file in img_names]\n",
        "  return image_data,image_labels\n",
        "\n",
        "# get image data and labels\n",
        "image_data,image_labels = preprocess_data(img_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DseTTDYAmgxm",
        "outputId": "328ddfc0-1de5-46ee-be75-5dcf3f00eef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15, 77760)\n"
          ]
        }
      ],
      "source": [
        "# get representative image data for each subject with the help of PCA\n",
        "def get_sub_representative_image_arr(image_data):\n",
        "  pca_repre_sub_img_arr = []\n",
        "\n",
        "  for grp_idx in range(15):\n",
        "    scaler = StandardScaler()\n",
        "    img_matrix_per_group = image_data[grp_idx*6:grp_idx*6+6]\n",
        "    # print([grp_idx*6,grp_idx*6+6])\n",
        "    img_matrix_per_group = scaler.fit_transform(img_matrix_per_group)\n",
        "\n",
        "    pca = PCA(n_components = 1)\n",
        "    x_pca = pca.fit_transform(img_matrix_per_group)\n",
        "    x_pca_original = pca.inverse_transform(x_pca)\n",
        "    x_pca_reconstructed = scaler.inverse_transform(x_pca_original)\n",
        "    pca_repre_sub_img_arr.append(x_pca_reconstructed[0]) # taking first component data only\n",
        "    # print(x_pca_reconstructed.shape)\n",
        "\n",
        "  pca_repre_sub_img_arr = np.array(pca_repre_sub_img_arr)\n",
        "  return pca_repre_sub_img_arr\n",
        "\n",
        "pca_repre_sub_img_arr = get_sub_representative_image_arr(image_data)\n",
        "print(pca_repre_sub_img_arr.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XRPoM70qmlcf"
      },
      "outputs": [],
      "source": [
        "def predict_class(image_number, image_data, image_labels):\n",
        "  pca_repre_sub_img_arr = get_sub_representative_image_arr(image_data) # get representative PCA array of subjects\n",
        "  org_img_data = image_data[image_number-1] # get original data for image\n",
        "  euclidean_dist_arr = []\n",
        "  # get euclidean distance from each subject representative image\n",
        "  for sub_idx in range(len(pca_repre_sub_img_arr)):\n",
        "    euclidean_dist_arr.append(np.linalg.norm(pca_repre_sub_img_arr[sub_idx] - org_img_data))\n",
        "\n",
        "  predicted_class = np.argmin(euclidean_dist_arr) + 1\n",
        "  return predicted_class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo3KdcmCmnyf",
        "outputId": "39b5bef9-5f71-4648-9610-ee266581e524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted class is : 11\n"
          ]
        }
      ],
      "source": [
        "image_number = 64\n",
        "# call the function\n",
        "predicted_class = predict_class(image_number, image_data, image_labels)\n",
        "print('Predicted class is :',predicted_class)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
