{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94d84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42da91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import KNNImputer ,SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "418ec25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7f12e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (15000, 20)\n",
      "Test shape: (10000, 19)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eea00597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable distribution:\n",
      "Status\n",
      "C     67.340000\n",
      "D     30.246667\n",
      "CL     2.413333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for the target variable distribution\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(train_df['Status'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c274bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "def analyze_missing_values(df, name):\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = missing / len(df) * 100\n",
    "    print(f\"\\nMissing values in {name} dataset:\")\n",
    "    for col, pct in zip(missing.index, missing_pct):\n",
    "        if pct > 0:\n",
    "            print(f\"{col}: {pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44eb6a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in train dataset:\n",
      "Drug: 43.67%\n",
      "Ascites: 43.61%\n",
      "Hepatomegaly: 43.67%\n",
      "Spiders: 43.69%\n",
      "Cholesterol: 55.58%\n",
      "Copper: 44.27%\n",
      "Alk_Phos: 43.70%\n",
      "SGOT: 43.71%\n",
      "Tryglicerides: 55.90%\n",
      "Platelets: 3.85%\n",
      "Prothrombin: 0.12%\n",
      "\n",
      "Missing values in test dataset:\n",
      "Drug: 42.84%\n",
      "Ascites: 42.82%\n",
      "Hepatomegaly: 42.87%\n",
      "Spiders: 42.89%\n",
      "Cholesterol: 55.47%\n",
      "Copper: 43.58%\n",
      "Alk_Phos: 42.91%\n",
      "SGOT: 42.92%\n",
      "Tryglicerides: 55.81%\n",
      "Platelets: 3.63%\n",
      "Prothrombin: 0.16%\n"
     ]
    }
   ],
   "source": [
    "analyze_missing_values(train_df, 'train')\n",
    "analyze_missing_values(test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52d1b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_train = train_df.drop('Status', axis=1).copy()\n",
    "y_train = train_df['Status'].copy()\n",
    "X_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f44b0d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess_data(X_train, y_train, X_test):\n",
    "    # Encode categorical target\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y_train)\n",
    "    print(f\"\\nEncoded target classes: {label_encoder.classes_}\")\n",
    "    \n",
    "    # Keep track of original indices\n",
    "    X_train['original_index'] = X_train.index\n",
    "    X_test['original_index'] = X_test.index\n",
    "    \n",
    "    # Identify data types\n",
    "    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    numeric_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "    numeric_cols.remove('original_index')  # Remove the index column we added\n",
    "    \n",
    "    print(f\"\\nCategorical columns: {categorical_cols}\")\n",
    "    print(f\"Numeric columns: {numeric_cols}\")\n",
    "    \n",
    "    # Strategy for handling missing values:\n",
    "    # 1. For categorical: impute with most frequent value\n",
    "    # 2. For numerical: use KNN imputation\n",
    "    \n",
    "    # Create pipeline for categorical features\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Use most frequent value for categorical imputation\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    # Create pipeline for numerical features\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Combine transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_cols),\n",
    "            ('num', numeric_transformer, numeric_cols)\n",
    "        ])\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    print(\"\\nPreprocessing data...\")\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    categorical_feature_names = []\n",
    "    if categorical_cols:\n",
    "        ohe = preprocessor.named_transformers_['cat'].named_steps['encoder']\n",
    "        categorical_feature_names = ohe.get_feature_names_out(categorical_cols).tolist()\n",
    "    \n",
    "    numeric_feature_names = numeric_cols\n",
    "    all_feature_names = categorical_feature_names + numeric_feature_names\n",
    "    \n",
    "    print(f\"Processed feature count: {len(all_feature_names)}\")\n",
    "    \n",
    "    return X_train_processed, y_encoded, X_test_processed, label_encoder, all_feature_names, X_train['original_index'], X_test['original_index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "845dd9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded target classes: ['C' 'CL' 'D']\n",
      "\n",
      "Categorical columns: ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n",
      "Numeric columns: ['id', 'N_Days', 'Age', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin', 'Stage']\n",
      "\n",
      "Preprocessing data...\n",
      "Processed feature count: 27\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "X_train_processed, y_encoded, X_test_processed, label_encoder, feature_names, train_indices, test_indices = preprocess_data(X_train, y_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dd14ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data shape: (12000, 27)\n",
      "Validation data shape: (3000, 27)\n",
      "Test data shape: (10000, 27)\n"
     ]
    }
   ],
   "source": [
    "# Create validation set\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_processed, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining data shape: {X_train_final.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Test data shape: {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e98ed061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train models\n",
    "def train_xgboost(X_train, y_train, X_val, y_val):\n",
    "    print(\"\\nTraining XGBoost model...\")\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    \n",
    "    if num_classes == 2:\n",
    "        objective = 'binary:logistic'\n",
    "        eval_metric = 'logloss'\n",
    "    else:\n",
    "        objective = 'multi:softprob'\n",
    "        eval_metric = 'mlogloss'\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=objective,\n",
    "        eval_metric=eval_metric,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[xgb.callback.EarlyStopping(rounds=20, save_best=True)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Get validation score\n",
    "    if num_classes == 2:\n",
    "        y_pred_val = model.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred_val)\n",
    "        y_pred_val_tensor = np.array(y_pred_val).reshape(-1, 1)\n",
    "        y_pred_val_complement = 1 - y_pred_val_tensor\n",
    "        y_pred_val_probs = np.hstack((y_pred_val_complement, y_pred_val_tensor))\n",
    "        loss = log_loss(y_val, y_pred_val_probs)\n",
    "    else:\n",
    "        y_pred_val = model.predict_proba(X_val)\n",
    "        auc = roc_auc_score(y_val, y_pred_val, multi_class='ovr')\n",
    "        loss = log_loss(y_val, y_pred_val)\n",
    "    \n",
    "    print(f\"XGBoost - Validation AUC: {auc:.4f}, Log Loss: {loss:.4f}\")\n",
    "    return model, auc, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8c3e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LBGM \n",
    "def train_lightgbm(X_train, y_train, X_val, y_val):\n",
    "    print(\"\\nTraining LightGBM model...\")\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    \n",
    "    if num_classes == 2:\n",
    "        objective = 'binary'\n",
    "        metric = 'binary_logloss'\n",
    "    else:\n",
    "        objective = 'multiclass'\n",
    "        metric = 'multi_logloss'\n",
    "    \n",
    "    model = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt',\n",
    "        num_leaves=31,\n",
    "        max_depth=-1,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=objective,\n",
    "        random_state=42,\n",
    "        metric=metric,\n",
    "        num_class=num_classes if num_classes > 2 else 1\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(20, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    # Get validation score\n",
    "    if num_classes == 2:\n",
    "        y_pred_val = model.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred_val)\n",
    "        loss = log_loss(y_val, model.predict_proba(X_val))\n",
    "    else:\n",
    "        y_pred_val = model.predict_proba(X_val)\n",
    "        auc = roc_auc_score(y_val, y_pred_val, multi_class='ovr')\n",
    "        loss = log_loss(y_val, y_pred_val)\n",
    "    \n",
    "    print(f\"LightGBM - Validation AUC: {auc:.4f}, Log Loss: {loss:.4f}\")\n",
    "    return model, auc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "387e49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost(X_train, y_train, X_val, y_val):\n",
    "    print(\"\\nTraining CatBoost model...\")\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    \n",
    "    if num_classes == 2:\n",
    "        loss_function = 'Logloss'\n",
    "    else:\n",
    "        loss_function = 'MultiClass'\n",
    "    \n",
    "    model = cb.CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=3,\n",
    "        loss_function=loss_function,\n",
    "        eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Get validation score\n",
    "    if num_classes == 2:\n",
    "        y_pred_val = model.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred_val)\n",
    "        loss = log_loss(y_val, model.predict_proba(X_val))\n",
    "    else:\n",
    "        y_pred_val = model.predict_proba(X_val)\n",
    "        auc = roc_auc_score(y_val, y_pred_val, multi_class='ovr')\n",
    "        loss = log_loss(y_val, y_pred_val)\n",
    "    \n",
    "    print(f\"CatBoost - Validation AUC: {auc:.4f}, Log Loss: {loss:.4f}\")\n",
    "    return model, auc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86cf0f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "XGBClassifier.fit() got an unexpected keyword argument 'callbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train all models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m xgb_model, xgb_auc, xgb_loss \u001b[38;5;241m=\u001b[39m train_xgboost(X_train_final, y_train_final, X_val, y_val)\n\u001b[0;32m      3\u001b[0m lgb_model, lgb_auc, lgb_loss \u001b[38;5;241m=\u001b[39m train_lightgbm(X_train_final, y_train_final, X_val, y_val)\n\u001b[0;32m      4\u001b[0m cb_model, cb_auc, cb_loss \u001b[38;5;241m=\u001b[39m train_catboost(X_train_final, y_train_final, X_val, y_val)\n",
      "Cell \u001b[1;32mIn[33], line 27\u001b[0m, in \u001b[0;36mtrain_xgboost\u001b[1;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     11\u001b[0m     eval_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\n\u001b[0;32m     14\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[0;32m     15\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     28\u001b[0m     X_train, y_train,\n\u001b[0;32m     29\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39m[(X_val, y_val)],\n\u001b[0;32m     30\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[xgb\u001b[38;5;241m.\u001b[39mcallback\u001b[38;5;241m.\u001b[39mEarlyStopping(rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, save_best\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)],\n\u001b[0;32m     31\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Get validation score\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_classes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\Applications\\Anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: XGBClassifier.fit() got an unexpected keyword argument 'callbacks'"
     ]
    }
   ],
   "source": [
    "# Train all models\n",
    "xgb_model, xgb_auc, xgb_loss = train_xgboost(X_train_final, y_train_final, X_val, y_val)\n",
    "lgb_model, lgb_auc, lgb_loss = train_lightgbm(X_train_final, y_train_final, X_val, y_val)\n",
    "cb_model, cb_auc, cb_loss = train_catboost(X_train_final, y_train_final, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ea73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble weights based on validation performance\n",
    "# We use inverse of log loss as weight (lower loss = higher weight)\n",
    "weights = np.array([1/xgb_loss, 1/lgb_loss, 1/cb_loss])\n",
    "weights = weights / weights.sum()  # Normalize to sum to 1\n",
    "print(f\"\\nEnsemble weights: XGBoost={weights[0]:.3f}, LightGBM={weights[1]:.3f}, CatBoost={weights[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdacf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "if num_classes == 2:\n",
    "    val_pred_xgb = xgb_model.predict_proba(X_val)[:, 1]\n",
    "    val_pred_lgb = lgb_model.predict_proba(X_val)[:, 1]\n",
    "    val_pred_cb = cb_model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    val_pred_ensemble = (\n",
    "        weights[0] * val_pred_xgb +\n",
    "        weights[1] * val_pred_lgb +\n",
    "        weights[2] * val_pred_cb\n",
    "    )\n",
    "    \n",
    "    # Evaluate ensemble\n",
    "    ensemble_auc = roc_auc_score(y_val, val_pred_ensemble)\n",
    "    # For log loss we need probabilities for both classes\n",
    "    ensemble_probs = np.column_stack((1 - val_pred_ensemble, val_pred_ensemble))\n",
    "    ensemble_loss = log_loss(y_val, ensemble_probs)\n",
    "else:\n",
    "    val_pred_xgb = xgb_model.predict_proba(X_val)\n",
    "    val_pred_lgb = lgb_model.predict_proba(X_val)\n",
    "    val_pred_cb = cb_model.predict_proba(X_val)\n",
    "    \n",
    "    val_pred_ensemble = (\n",
    "        weights[0] * val_pred_xgb +\n",
    "        weights[1] * val_pred_lgb +\n",
    "        weights[2] * val_pred_cb\n",
    "    )\n",
    "    \n",
    "    # Evaluate ensemble\n",
    "    ensemble_auc = roc_auc_score(y_val, val_pred_ensemble, multi_class='ovr')\n",
    "    ensemble_loss = log_loss(y_val, val_pred_ensemble)\n",
    "\n",
    "print(f\"\\nEnsemble - Validation AUC: {ensemble_auc:.4f}, Log Loss: {ensemble_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993bf213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "if num_classes == 2:\n",
    "    test_pred_xgb = xgb_model.predict_proba(X_test_processed)[:, 1]\n",
    "    test_pred_lgb = lgb_model.predict_proba(X_test_processed)[:, 1]\n",
    "    test_pred_cb = cb_model.predict_proba(X_test_processed)[:, 1]\n",
    "    \n",
    "    test_pred_ensemble = (\n",
    "        weights[0] * test_pred_xgb +\n",
    "        weights[1] * test_pred_lgb +\n",
    "        weights[2] * test_pred_cb\n",
    "    )\n",
    "    \n",
    "    # Convert to class probabilities\n",
    "    test_pred_probs = np.column_stack((1 - test_pred_ensemble, test_pred_ensemble))\n",
    "else:\n",
    "    test_pred_xgb = xgb_model.predict_proba(X_test_processed)\n",
    "    test_pred_lgb = lgb_model.predict_proba(X_test_processed)\n",
    "    test_pred_cb = cb_model.predict_proba(X_test_processed)\n",
    "    \n",
    "    test_pred_ensemble = (\n",
    "        weights[0] * test_pred_xgb +\n",
    "        weights[1] * test_pred_lgb +\n",
    "        weights[2] * test_pred_cb\n",
    "    )\n",
    "    \n",
    "    test_pred_probs = test_pred_ensemble\n",
    "\n",
    "# Create the submission DataFrame matching the required format\n",
    "results_df = pd.DataFrame({\n",
    "    'id': test_indices\n",
    "})\n",
    "\n",
    "# Add probability columns for each class with the exact column names from the submission format\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    results_df[f'Status_{class_name}'] = test_pred_probs[:, i]\n",
    "\n",
    "# Sort by original index to maintain original order\n",
    "results_df = results_df.sort_values('id').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFirst few predictions:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c39a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "results_df.to_csv('ensemble_predictions.csv', index=False)\n",
    "print(\"\\nPredictions saved to 'ensemble_predictions.csv' with columns:\", results_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2354fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature importance visualization for the base models\n",
    "def print_feature_importance(model, model_name, feature_names):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        print(f\"\\nTop 10 features for {model_name}:\")\n",
    "        for i in range(min(10, len(feature_names))):\n",
    "            idx = indices[i]\n",
    "            if idx < len(feature_names):\n",
    "                print(f\"{feature_names[idx]}: {importances[idx]:.4f}\")\n",
    "\n",
    "# Print feature importances\n",
    "print_feature_importance(xgb_model, \"XGBoost\", feature_names)\n",
    "print_feature_importance(lgb_model, \"LightGBM\", feature_names)\n",
    "print_feature_importance(cb_model, \"CatBoost\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19887403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for more robust evaluation\n",
    "def cross_validate_ensemble(X, y, n_splits=5):\n",
    "    print(\"\\nPerforming cross-validation...\")\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    cv_aucs = []\n",
    "    cv_losses = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold {fold+1}/{n_splits}\")\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Train models\n",
    "        xgb_model, xgb_auc, xgb_loss = train_xgboost(X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
    "        lgb_model, lgb_auc, lgb_loss = train_lightgbm(X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
    "        cb_model, cb_auc, cb_loss = train_catboost(X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
    "        \n",
    "        # Weight models\n",
    "        weights = np.array([1/xgb_loss, 1/lgb_loss, 1/cb_loss])\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        # Make ensemble prediction\n",
    "        num_classes = len(np.unique(y))\n",
    "        if num_classes == 2:\n",
    "            val_pred_xgb = xgb_model.predict_proba(X_val_fold)[:, 1]\n",
    "            val_pred_lgb = lgb_model.predict_proba(X_val_fold)[:, 1]\n",
    "            val_pred_cb = cb_model.predict_proba(X_val_fold)[:, 1]\n",
    "            \n",
    "            val_pred_ensemble = (\n",
    "                weights[0] * val_pred_xgb +\n",
    "                weights[1] * val_pred_lgb +\n",
    "                weights[2] * val_pred_cb\n",
    "            )\n",
    "            \n",
    "            # Evaluate ensemble\n",
    "            fold_auc = roc_auc_score(y_val_fold, val_pred_ensemble)\n",
    "            # For log loss we need probabilities for both classes\n",
    "            ensemble_probs = np.column_stack((1 - val_pred_ensemble, val_pred_ensemble))\n",
    "            fold_loss = log_loss(y_val_fold, ensemble_probs)\n",
    "        else:\n",
    "            val_pred_xgb = xgb_model.predict_proba(X_val_fold)\n",
    "            val_pred_lgb = lgb_model.predict_proba(X_val_fold)\n",
    "            val_pred_cb = cb_model.predict_proba(X_val_fold)\n",
    "            \n",
    "            val_pred_ensemble = (\n",
    "                weights[0] * val_pred_xgb +\n",
    "                weights[1] * val_pred_lgb +\n",
    "                weights[2] * val_pred_cb\n",
    "            )\n",
    "            \n",
    "            # Evaluate ensemble\n",
    "            fold_auc = roc_auc_score(y_val_fold, val_pred_ensemble, multi_class='ovr')\n",
    "            fold_loss = log_loss(y_val_fold, val_pred_ensemble)\n",
    "        \n",
    "        cv_aucs.append(fold_auc)\n",
    "        cv_losses.append(fold_loss)\n",
    "        print(f\"Fold {fold+1} - AUC: {fold_auc:.4f}, Log Loss: {fold_loss:.4f}\")\n",
    "    \n",
    "    print(f\"\\nCross-validation results:\")\n",
    "    print(f\"Mean AUC: {np.mean(cv_aucs):.4f} ± {np.std(cv_aucs):.4f}\")\n",
    "    print(f\"Mean Log Loss: {np.mean(cv_losses):.4f} ± {np.std(cv_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df241ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "cross_validate_ensemble(X_train_processed, y_encoded)\n",
    "\n",
    "print(\"\\nModel training and evaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
