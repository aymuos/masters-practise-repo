{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Using cached pandas-2.3.3-cp314-cp314-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Collecting numpy>=1.26.0 (from pandas)\n",
            "  Using cached numpy-2.3.5-cp314-cp314-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Using cached pandas-2.3.3-cp314-cp314-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.3 MB)\n",
            "Using cached numpy-2.3.5-cp314-cp314-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Installing collected packages: pytz, tzdata, numpy, pandas\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [pandas]2m3/4\u001b[0m [pandas]\n",
            "\u001b[1A\u001b[2KSuccessfully installed numpy-2.3.5 pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "MIHum7ocP0eF",
        "outputId": "56da6f94-cdb0-4ede-8678-2aa541c3dc56"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'scipy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msignal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m welch, correlate\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m kurtosis\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLoopAnalyzer\u001b[39;00m:\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scipy'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import welch, correlate\n",
        "from scipy.stats import kurtosis\n",
        "\n",
        "class LoopAnalyzer:\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path = file_path\n",
        "        self.data = pd.read_csv(file_path)\n",
        "        self.results = {}\n",
        "\n",
        "    def _identify_columns(self):\n",
        "        \"\"\"Automatically maps columns based on names.\"\"\"\n",
        "        cols = {c.lower(): c for c in self.data.columns}\n",
        "        self.pv_col = next((c for c in cols if 'pv' in c), None)\n",
        "        self.sp_col = next((c for c in cols if 'sp' in c), None)\n",
        "        self.op_col = next((c for c in cols if 'op' in c), None)\n",
        "\n",
        "        if not all([self.pv_col, self.sp_col, self.op_col]):\n",
        "            raise ValueError(\"Could not auto-identify PV, SP, or OP columns.\")\n",
        "\n",
        "    def analyze(self):\n",
        "        self._identify_columns()\n",
        "\n",
        "        pv = self.data[self.pv_col].values\n",
        "        sp = self.data[self.sp_col].values\n",
        "        op = self.data[self.op_col].values\n",
        "\n",
        "        # 1. Basic Error Calculation\n",
        "        error = sp - pv\n",
        "        mse = np.mean(error**2) # Variance / Performance Proxy\n",
        "\n",
        "        # 2. Noise Detection (High Frequency Variation)\n",
        "        # Ratio of \"jumpiness\" (diff) to \"range\" (std).\n",
        "        # High ratio = signal is mostly noise, not process movement.\n",
        "        pv_std = np.std(pv) + 1e-9\n",
        "        noise_metric = np.std(np.diff(pv)) / pv_std\n",
        "        is_noisy = noise_metric > 0.5  # Threshold: 50% of variation is high-freq noise\n",
        "\n",
        "        # 3. Oscillation Detection (Spectral Analysis)\n",
        "        # Calculate Power Spectral Density\n",
        "        f, Pxx = welch(error - np.mean(error), nperseg=min(len(error), 256))\n",
        "        total_power = np.sum(Pxx)\n",
        "        max_power = np.max(Pxx)\n",
        "        oscillation_index = max_power / (total_power + 1e-9)\n",
        "\n",
        "        is_oscillating = oscillation_index > 0.1 # Threshold: Dominant freq has >10% of power\n",
        "\n",
        "        # 4. Stiction Probability Estimation\n",
        "        # Heuristic: Stiction causes oscillation + Non-Gaussian Error (Square/Triangular waves)\n",
        "        # Stiction probability is high if: Loop is Oscillating AND Error Kurtosis is low (Square wave < 2.0)\n",
        "        kurt = kurtosis(error)\n",
        "        stiction_prob = 0\n",
        "\n",
        "        if is_oscillating:\n",
        "            base_prob = 60.0\n",
        "            # If wave is \"squarish\" (low kurtosis), stiction is more likely\n",
        "            shape_factor = 20.0 if kurt < 2.5 else 0\n",
        "            stiction_prob = base_prob + shape_factor + (oscillation_index * 20)\n",
        "        else:\n",
        "            # Low probability if no oscillation, but could be 'Stick-Slip'\n",
        "            stiction_prob = 5.0\n",
        "\n",
        "        stiction_prob = min(stiction_prob, 99.9)\n",
        "\n",
        "        # 5. Disturbance Detection\n",
        "        # Significant error but NOT oscillating\n",
        "        is_disturbance = (mse > 1.0) and (not is_oscillating) and (np.std(sp) < 0.1)\n",
        "\n",
        "        # Store Results\n",
        "        self.results = {\n",
        "            \"Loop Name\": self.file_path.split('/')[-1],\n",
        "            \"MSE (Variance)\": round(mse, 4),\n",
        "            \"Noise Level (Ratio)\": round(noise_metric, 2),\n",
        "            \"Oscillation Index\": round(oscillation_index, 2),\n",
        "            \"Stiction Probability (%)\": round(stiction_prob, 1),\n",
        "            \"Behaviors Detected\": []\n",
        "        }\n",
        "\n",
        "        # Generate Inferences\n",
        "        if is_noisy: self.results[\"Behaviors Detected\"].append(\"Noisy Sensor Signal\")\n",
        "        if is_oscillating: self.results[\"Behaviors Detected\"].append(\"Significant Oscillation\")\n",
        "        if is_disturbance: self.results[\"Behaviors Detected\"].append(\"External Disturbance\")\n",
        "        if stiction_prob > 50: self.results[\"Behaviors Detected\"].append(\"High Valve Stiction Risk\")\n",
        "        if not self.results[\"Behaviors Detected\"] and mse < 1.0:\n",
        "            self.results[\"Behaviors Detected\"].append(\"Stable / Well-Tuned\")\n",
        "\n",
        "        return self.results\n",
        "\n",
        "# --- Example Usage with the provided file ---\n",
        "analyzer = LoopAnalyzer('loop_1_loop.csv')\n",
        "report = analyzer.analyze()\n",
        "\n",
        "# Display Comprehensive Summary\n",
        "print(\"-\" * 40)\n",
        "print(f\"Loop Analysis Report: {report['Loop Name']}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Condition              | Value\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Control Variance (MSE) | {report['MSE (Variance)']}\")\n",
        "print(f\"Oscillation Index      | {report['Oscillation Index']} (Threshold > 0.1)\")\n",
        "print(f\"Noise Ratio            | {report['Noise Level (Ratio)']} (Threshold > 0.5)\")\n",
        "print(f\"Stiction Probability   | {report['Stiction Probability (%)']}%\")\n",
        "print(\"-\" * 40)\n",
        "print(\"AUTOMATED INFERENCES:\")\n",
        "for inference in report['Behaviors Detected']:\n",
        "    print(f\"• {inference}\")\n",
        "print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-dVV8kFWLqm",
        "outputId": "08f33f5a-b078-4d89-e7f7-f6bfb109e2f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "Description >>>  100\n",
            "Features >>>  100\n",
            "Merged DataFrame Head:\n",
            "        mse       mae  error_std  noise_metric  noise_ratio  \\\n",
            "0  0.000030  0.004235   0.005454      0.000234     0.023052   \n",
            "1  0.001045  0.025571   0.032332      0.017812     0.592497   \n",
            "2  0.119583  0.280936   0.345769      0.053442     0.154560   \n",
            "3  0.002643  0.037581   0.051404      0.040104     0.179440   \n",
            "4  0.000824  0.022811   0.028635      0.022426     0.783154   \n",
            "\n",
            "   oscillation_strength  error_kurtosis  error_skew  pv_op_lag  loop_no  \\\n",
            "0              0.100876        0.939374   -0.193102          0        1   \n",
            "1              0.076720        0.270480   -0.128951          4        2   \n",
            "2              0.232022       -0.276325   -0.149960        206        3   \n",
            "3              0.039037       60.624015    3.424605          4        4   \n",
            "4              0.039180        0.025652   -0.298246       2351        5   \n",
            "\n",
            "   oscillatory? noisy disturbance                         comments  \\\n",
            "0           0.0   Yes          No                          Only PV   \n",
            "1           1.0    No          No  Looks intermittenly oscillatory   \n",
            "2           1.0    No   Yes at PV        Seems to be like stiction   \n",
            "3           1.0    No          No              looks like stiction   \n",
            "4           0.0    No          No               Process lag exists   \n",
            "\n",
            "   sticky_valve_probability_  \n",
            "0                       1.00  \n",
            "1                      38.04  \n",
            "2                       5.00  \n",
            "3                      50.19  \n",
            "4                       6.95  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from scipy.signal import welch, correlate\n",
        "from scipy.stats import kurtosis, skew\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, mean_squared_error\n",
        "\n",
        "# ==========================================\n",
        "# PART 1: CONFIGURATION & UTILS\n",
        "# ==========================================\n",
        "CONFIG = {\n",
        "    'description_file': 'Loop description.xlsx', # Update path\n",
        "    'data_folder': 'data', # Changed to current directory to find CSVs\n",
        "    'test_size': 0.2,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "def clean_binary_target(val):\n",
        "    \"\"\"\n",
        "    Parses messy text labels (e.g., 'Yes, highly oscillatory', 'may be')\n",
        "    into binary integers (0 or 1).\n",
        "    \"\"\"\n",
        "    if pd.isna(val):\n",
        "        return 0\n",
        "    val = str(val).lower().strip()\n",
        "\n",
        "    # Positive keywords indicative of the condition\n",
        "    positive_keywords = [\n",
        "        'yes', 'high', 'oscillat', 'noise', 'sticky', 'bad','Oscillatory','Yes, long oscillation''Oscillating SP','variance high','Yes + high variance','Yes (Intermittent)'\n",
        "        'ripples', 'disturbance', 'instability','Highly Oscillatory','Yes , Long oscillation','Yes. Oscillatory','Highly intermittenly oscillatory'\n",
        "    ]\n",
        "\n",
        "    if any(keyword.lower() in val for keyword in positive_keywords):\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# ==========================================\n",
        "# PART 2: FEATURE ENGINEERING (THE ANALYZER)\n",
        "# ==========================================\n",
        "class LoopFeatureExtractor:\n",
        "    \"\"\"\n",
        "    Extracts statistical and signal processing features from Loop Data.\n",
        "    \"\"\"\n",
        "\n",
        "    def extract_features(self, filepath):\n",
        "        try:\n",
        "            df = pd.read_csv(filepath)\n",
        "            # Normalize column names\n",
        "            df.columns = [c.lower() for c in df.columns]\n",
        "\n",
        "            # Identify columns dynamically\n",
        "            pv_col = next((c for c in df.columns if 'pv' in c), None)\n",
        "            sp_col = next((c for c in df.columns if 'sp' in c), None)\n",
        "            op_col = next((c for c in df.columns if 'op' in c), None)\n",
        "\n",
        "            if not (pv_col and sp_col and op_col):\n",
        "                return None # Skip invalid files\n",
        "\n",
        "            pv = df[pv_col].values\n",
        "            sp = df[sp_col].values\n",
        "            op = df[op_col].values\n",
        "\n",
        "            # --- CALCULATIONS ---\n",
        "\n",
        "            # 1. Error Signal\n",
        "            error = sp - pv\n",
        "\n",
        "            # 2. Basic Statistics\n",
        "            mse = np.mean(error**2)\n",
        "            mae = np.mean(np.abs(error))\n",
        "            error_std = np.std(error)\n",
        "\n",
        "            # 3. Noise Estimation (High Frequency)\n",
        "            # Ratio of diff_std (jumps) to signal_std (range)\n",
        "            pv_diff = np.diff(pv)\n",
        "            noise_metric = np.std(pv_diff)\n",
        "            noise_ratio = noise_metric / (np.std(pv) + 1e-9)\n",
        "\n",
        "            # 4. Oscillation Detection (Spectral Analysis)\n",
        "            # Power Spectral Density using Welch's method\n",
        "            f, Pxx = welch(error - np.mean(error), nperseg=min(len(error), 256))\n",
        "            total_power = np.sum(Pxx)\n",
        "            max_power = np.max(Pxx)\n",
        "            oscillation_strength = max_power / (total_power + 1e-9) # Spectral Peak Ratio\n",
        "\n",
        "            # 5. Non-Linearity / Stiction Features\n",
        "            # Stiction often creates square waves (low Kurtosis) or specific PV-OP shapes\n",
        "            err_kurtosis = kurtosis(error)\n",
        "            err_skew = skew(error)\n",
        "\n",
        "            # PV-OP Correlation Lag\n",
        "            # Normalize for correlation\n",
        "            norm_pv = (pv - np.mean(pv)) / (np.std(pv) + 1e-9)\n",
        "            norm_op = (op - np.mean(op)) / (np.std(op) + 1e-9)\n",
        "            xcorr = correlate(norm_pv, norm_op, mode='full')\n",
        "            lag_index = np.argmax(xcorr)\n",
        "            center_index = len(norm_pv) - 1\n",
        "            lag = abs(lag_index - center_index)\n",
        "\n",
        "            return {\n",
        "                'mse': mse,\n",
        "                'mae': mae,\n",
        "                'error_std': error_std,\n",
        "                'noise_metric': noise_metric,\n",
        "                'noise_ratio': noise_ratio,\n",
        "                'oscillation_strength': oscillation_strength,\n",
        "                'error_kurtosis': err_kurtosis,\n",
        "                'error_skew': err_skew,\n",
        "                'pv_op_lag': lag\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filepath}: {e}\")\n",
        "            return None\n",
        "\n",
        "# ==========================================\n",
        "# PART 3: MAIN EXECUTION AND DATA PREP\n",
        "# ==========================================\n",
        "\n",
        "# Load Loop Descriptions (Ground Truth)\n",
        "# Use pd.read_excel for .xlsx files\n",
        "try:\n",
        "    description_df = pd.read_excel('/content/Loop description.xlsx')\n",
        "    description_df.columns = [c.lower().replace(' ', '_') for c in description_df.columns]\n",
        "\n",
        "    # Apply cleaning function to relevant target columns\n",
        "    # for col in ['loop_no', 'oscillatory', 'noisy', 'sticky_valve_probability', 'disturbance']:\n",
        "    for col in ['oscillatory?']:\n",
        "        if col in description_df.columns:\n",
        "            description_df[col] = description_df[col].apply(clean_binary_target)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading description file: {e}\")\n",
        "    description_df = pd.DataFrame() # Create empty DF on error\n",
        "\n",
        "# Extract Features from Loop Data\n",
        "feature_extractor = LoopFeatureExtractor()\n",
        "all_features = []\n",
        "\n",
        "# Assuming loop files are in the same directory for this example\n",
        "loop_files = glob.glob('data_folder/loop_*.csv')\n",
        "loop_name =1\n",
        "for f_path in loop_files:\n",
        "    features = feature_extractor.extract_features(f_path)\n",
        "    if features:\n",
        "       # loop_name = os.path.basename(f_path).replace('.csv', '')\n",
        "        features['loop_no'] = loop_name\n",
        "        all_features.append(features)\n",
        "        loop_name +=1\n",
        "\n",
        "features_df = pd.DataFrame(all_features)\n",
        "print(features_df.shape[0])\n",
        "merged_df=[]\n",
        "# Merge Features with Descriptions\n",
        "if not description_df.empty and not features_df.empty:\n",
        "    # Ensure 'loop_name' is the key in both DFs for merging\n",
        "    # description_df might have 'loop_id' or similar, so rename if necessary\n",
        "    if 'Loop No' in description_df.columns:\n",
        "        description_df = description_df.rename(columns={'Loop No': 'loop_no'})\n",
        "\n",
        "    print(\"Description >>> \",description_df.shape[0])\n",
        "    print(\"Features >>> \",features_df.shape[0])\n",
        "\n",
        "    # Perform the merge\n",
        "    merged_df = pd.merge(features_df, description_df, on='loop_no', how='left')\n",
        "    print(\"Merged DataFrame Head:\")\n",
        "    print(merged_df.head())\n",
        "    feature_names = merged_df.columns.tolist()\n",
        "    feature_names.remove('loop_no')\n",
        "elif not features_df.empty:\n",
        "    print(\"Description DataFrame is empty or could not be loaded. Only features DataFrame is available.\")\n",
        "else:\n",
        "    print(\"Description or features DataFrame is empty. Cannot merge.\")\n",
        "\n",
        "    merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63PZFO4nVFVA",
        "outputId": "56f78b85-1d2b-45b1-e0b0-32662fc42f6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training DataFrame (70 samples):\n",
            "\n",
            "   loop_no  oscillation_strength  target\n",
            "0        1              0.100876     0.0\n",
            "1        2              0.076720     1.0\n",
            "2        3              0.232022     1.0\n",
            "3        4              0.039037     1.0\n",
            "4        5              0.039180     0.0\n",
            "\n",
            "------------------------------\n",
            "Model Test Accuracy: 64.29%\n",
            "------------------------------\n",
            "Feature Importance (Top 3):\n",
            "• noise_ratio: 0.2364\n",
            "• error_kurtosis: 0.1724\n",
            "• error_skew: 0.1529\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define feature_names from the available features, excluding non-feature columns\n",
        "feature_names = [\n",
        "    'mse', 'mae', 'error_std', 'noise_metric', 'noise_ratio',\n",
        "    'oscillation_strength', 'error_kurtosis', 'error_skew', 'pv_op_lag'\n",
        "]\n",
        "\n",
        "# Create the targets DataFrame from merged_df\n",
        "targets = merged_df[['loop_no', 'oscillatory?']].rename(columns={'oscillatory?': 'target'})\n",
        "\n",
        "# Create DataFrame\n",
        "X_df = pd.DataFrame(merged_df, columns=['loop_no'] + feature_names)\n",
        "train_df = X_df.merge(targets, on='loop_no') # Removed 'Loop No' as 'loop_no' is the common key\n",
        "\n",
        "# --- Cleaning step: Remove rows with NaN in the target variable ---\n",
        "train_df.dropna(subset=['target'], inplace=True)\n",
        "\n",
        "print(f\"Training DataFrame ({len(train_df)} samples):\\n\")\n",
        "print(train_df[['loop_no', 'oscillation_strength', 'target']].head())\n",
        "\n",
        "# ==========================================\n",
        "# 4. TRAIN MODEL (Gradient Boosting)\n",
        "# ==========================================\n",
        "X = train_df[feature_names]\n",
        "y = train_df['target']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# GradientBoostingClassifier is the sklearn equivalent of XGBoost\n",
        "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ==========================================\n",
        "# 5. RESULTS & INTERPRETATION\n",
        "# ==========================================\n",
        "preds_test = model.predict(X_test)\n",
        "acc_test = accuracy_score(y_test, preds_test)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 30)\n",
        "print(f\"Model Test Accuracy: {acc_test*100:.2f}%\")\n",
        "print(\"-\" * 30)\n",
        "print(\"Feature Importance (Top 3):\")\n",
        "importances = sorted(zip(feature_names, model.feature_importances_), key=lambda x: x[1], reverse=True)\n",
        "for name, val in importances[:3]:\n",
        "    print(f\"• {name}: {val:.4f}\")\n",
        "print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93881d25"
      },
      "source": [
        "# Task\n",
        "Update cell `q-dVV8kFWLqm` to apply the `clean_binary_target` function to 'noisy' and 'disturbance' columns, then train a multi-output regression model in cell `63PZFO4nVFVA` using `MultiOutputRegressor` with `GradientBoostingRegressor` to predict 'oscillatory?', 'noisy', 'disturbance', and 'sticky_valve_probability_'. Evaluate the model using accuracy for the binary targets and Mean Squared Error for the regression target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2aa9b8d"
      },
      "source": [
        "## Update Data Cleaning for Multi-Output Targets\n",
        "\n",
        "### Subtask:\n",
        "Modify cell `q-dVV8kFWLqm` to apply the `clean_binary_target` function to 'noisy' and 'disturbance' columns, ensuring all binary classification targets are correctly processed before model training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e12ddbd"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying cell `q-dVV8kFWLqm` to apply the `clean_binary_target` function to 'noisy' and 'disturbance' columns. I will update the code in that cell to include these columns in the cleaning process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a14b56a",
        "outputId": "c9093dc3-dcd0-4390-f84f-4efa0a9cec65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "Description >>>  100\n",
            "Features >>>  100\n",
            "Merged DataFrame Head:\n",
            "        mse       mae  error_std  noise_metric  noise_ratio  \\\n",
            "0  0.000030  0.004235   0.005454      0.000234     0.023052   \n",
            "1  0.001045  0.025571   0.032332      0.017812     0.592497   \n",
            "2  0.119583  0.280936   0.345769      0.053442     0.154560   \n",
            "3  0.002643  0.037581   0.051404      0.040104     0.179440   \n",
            "4  0.000824  0.022811   0.028635      0.022426     0.783154   \n",
            "\n",
            "   oscillation_strength  error_kurtosis  error_skew  pv_op_lag  loop_no  \\\n",
            "0              0.100876        0.939374   -0.193102          0        1   \n",
            "1              0.076720        0.270480   -0.128951          4        2   \n",
            "2              0.232022       -0.276325   -0.149960        206        3   \n",
            "3              0.039037       60.624015    3.424605          4        4   \n",
            "4              0.039180        0.025652   -0.298246       2351        5   \n",
            "\n",
            "   oscillatory?  noisy  disturbance                         comments  \\\n",
            "0           0.0    1.0          0.0                          Only PV   \n",
            "1           1.0    0.0          0.0  Looks intermittenly oscillatory   \n",
            "2           1.0    0.0          1.0        Seems to be like stiction   \n",
            "3           1.0    0.0          0.0              looks like stiction   \n",
            "4           0.0    0.0          0.0               Process lag exists   \n",
            "\n",
            "   sticky_valve_probability_  \n",
            "0                       1.00  \n",
            "1                      38.04  \n",
            "2                       5.00  \n",
            "3                      50.19  \n",
            "4                       6.95  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from scipy.signal import welch, correlate\n",
        "from scipy.stats import kurtosis, skew\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, mean_squared_error\n",
        "\n",
        "# ==========================================\n",
        "# PART 1: CONFIGURATION & UTILS\n",
        "# ==========================================\n",
        "CONFIG = {\n",
        "    'description_file': 'Loop description.xlsx', # Update path\n",
        "    'data_folder': 'data', # Changed to current directory to find CSVs\n",
        "    'test_size': 0.2,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "def clean_binary_target(val):\n",
        "    \"\"\"\n",
        "    Parses messy text labels (e.g., 'Yes, highly oscillatory', 'may be')\n",
        "    into binary integers (0 or 1).\n",
        "    \"\"\"\n",
        "    if pd.isna(val):\n",
        "        return 0\n",
        "    val = str(val).lower().strip()\n",
        "\n",
        "    # Positive keywords indicative of the condition\n",
        "    positive_keywords = [\n",
        "        'yes', 'high', 'oscillat', 'noise', 'sticky', 'bad','Oscillatory','Yes, long oscillation''Oscillating SP','variance high','Yes + high variance','Yes (Intermittent)'\n",
        "        'ripples', 'disturbance', 'instability','Highly Oscillatory','Yes , Long oscillation','Yes. Oscillatory','Highly intermittenly oscillatory'\n",
        "    ]\n",
        "\n",
        "    if any(keyword.lower() in val for keyword in positive_keywords):\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# ==========================================\n",
        "# PART 2: FEATURE ENGINEERING (THE ANALYZER)\n",
        "# ==========================================\n",
        "class LoopFeatureExtractor:\n",
        "    \"\"\"\n",
        "    Extracts statistical and signal processing features from Loop Data.\n",
        "    \"\"\"\n",
        "\n",
        "    def extract_features(self, filepath):\n",
        "        try:\n",
        "            df = pd.read_csv(filepath)\n",
        "            # Normalize column names\n",
        "            df.columns = [c.lower() for c in df.columns]\n",
        "\n",
        "            # Identify columns dynamically\n",
        "            pv_col = next((c for c in df.columns if 'pv' in c), None)\n",
        "            sp_col = next((c for c in df.columns if 'sp' in c), None)\n",
        "            op_col = next((c for c in df.columns if 'op' in c), None)\n",
        "\n",
        "            if not (pv_col and sp_col and op_col):\n",
        "                return None # Skip invalid files\n",
        "\n",
        "            pv = df[pv_col].values\n",
        "            sp = df[sp_col].values\n",
        "            op = df[op_col].values\n",
        "\n",
        "            # --- CALCULATIONS ---\n",
        "\n",
        "            # 1. Error Signal\n",
        "            error = sp - pv\n",
        "\n",
        "            # 2. Basic Statistics\n",
        "            mse = np.mean(error**2)\n",
        "            mae = np.mean(np.abs(error))\n",
        "            error_std = np.std(error)\n",
        "\n",
        "            # 3. Noise Estimation (High Frequency)\n",
        "            # Ratio of diff_std (jumps) to signal_std (range)\n",
        "            pv_diff = np.diff(pv)\n",
        "            noise_metric = np.std(pv_diff)\n",
        "            noise_ratio = noise_metric / (np.std(pv) + 1e-9)\n",
        "\n",
        "            # 4. Oscillation Detection (Spectral Analysis)\n",
        "            # Power Spectral Density using Welch's method\n",
        "            f, Pxx = welch(error - np.mean(error), nperseg=min(len(error), 256))\n",
        "            total_power = np.sum(Pxx)\n",
        "            max_power = np.max(Pxx)\n",
        "            oscillation_strength = max_power / (total_power + 1e-9) # Spectral Peak Ratio\n",
        "\n",
        "            # 5. Non-Linearity / Stiction Features\n",
        "            # Stiction often creates square waves (low Kurtosis) or specific PV-OP shapes\n",
        "            err_kurtosis = kurtosis(error)\n",
        "            err_skew = skew(error)\n",
        "\n",
        "            # PV-OP Correlation Lag\n",
        "            # Normalize for correlation\n",
        "            norm_pv = (pv - np.mean(pv)) / (np.std(pv) + 1e-9)\n",
        "            norm_op = (op - np.mean(op)) / (np.std(op) + 1e-9)\n",
        "            xcorr = correlate(norm_pv, norm_op, mode='full')\n",
        "            lag_index = np.argmax(xcorr)\n",
        "            center_index = len(norm_pv) - 1\n",
        "            lag = abs(lag_index - center_index)\n",
        "\n",
        "            return {\n",
        "                'mse': mse,\n",
        "                'mae': mae,\n",
        "                'error_std': error_std,\n",
        "                'noise_metric': noise_metric,\n",
        "                'noise_ratio': noise_ratio,\n",
        "                'oscillation_strength': oscillation_strength,\n",
        "                'error_kurtosis': err_kurtosis,\n",
        "                'error_skew': err_skew,\n",
        "                'pv_op_lag': lag\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filepath}: {e}\")\n",
        "            return None\n",
        "\n",
        "# ==========================================\n",
        "# PART 3: MAIN EXECUTION AND DATA PREP\n",
        "# ==========================================\n",
        "\n",
        "# Load Loop Descriptions (Ground Truth)\n",
        "# Use pd.read_excel for .xlsx files\n",
        "try:\n",
        "    description_df = pd.read_excel('/content/Loop description.xlsx')\n",
        "    description_df.columns = [c.lower().replace(' ', '_') for c in description_df.columns]\n",
        "\n",
        "    # Apply cleaning function to relevant target columns\n",
        "    for col in ['oscillatory?', 'noisy', 'disturbance']:\n",
        "        if col in description_df.columns:\n",
        "            description_df[col] = description_df[col].apply(clean_binary_target)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading description file: {e}\")\n",
        "    description_df = pd.DataFrame() # Create empty DF on error\n",
        "\n",
        "# Extract Features from Loop Data\n",
        "feature_extractor = LoopFeatureExtractor()\n",
        "all_features = []\n",
        "\n",
        "# Assuming loop files are in the same directory for this example\n",
        "loop_files = glob.glob('data_folder/loop_*.csv')\n",
        "loop_name =1\n",
        "for f_path in loop_files:\n",
        "    features = feature_extractor.extract_features(f_path)\n",
        "    if features:\n",
        "       # loop_name = os.path.basename(f_path).replace('.csv', '')\n",
        "        features['loop_no'] = loop_name\n",
        "        all_features.append(features)\n",
        "        loop_name +=1\n",
        "\n",
        "features_df = pd.DataFrame(all_features)\n",
        "print(features_df.shape[0])\n",
        "merged_df=[]\n",
        "# Merge Features with Descriptions\n",
        "if not description_df.empty and not features_df.empty:\n",
        "    # Ensure 'loop_name' is the key in both DFs for merging\n",
        "    # description_df might have 'loop_id' or similar, so rename if necessary\n",
        "    if 'Loop No' in description_df.columns:\n",
        "        description_df = description_df.rename(columns={'Loop No': 'loop_no'})\n",
        "\n",
        "    print(\"Description >>> \",description_df.shape[0])\n",
        "    print(\"Features >>> \",features_df.shape[0])\n",
        "\n",
        "    # Perform the merge\n",
        "    merged_df = pd.merge(features_df, description_df, on='loop_no', how='left')\n",
        "    print(\"Merged DataFrame Head:\")\n",
        "    print(merged_df.head())\n",
        "    feature_names = merged_df.columns.tolist()\n",
        "    feature_names.remove('loop_no')\n",
        "elif not features_df.empty:\n",
        "    print(\"Description DataFrame is empty or could not be loaded. Only features DataFrame is available.\")\n",
        "else:\n",
        "    print(\"Description or features DataFrame is empty. Cannot merge.\")\n",
        "\n",
        "    merged_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e8cf992"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying cell `63PZFO4nVFVA` to train a multi-output regression model. This involves preparing multiple target variables, using `MultiOutputRegressor` with `GradientBoostingRegressor`, and evaluating the model with appropriate metrics for both classification and regression targets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b7899d1",
        "outputId": "389ad5e0-0e0a-4282-af31-907cbac5f8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training DataFrame (70 samples) with multiple targets:\n",
            "   loop_no  oscillatory?  noisy  disturbance  sticky_valve_probability_\n",
            "0        1           0.0    1.0          0.0                       1.00\n",
            "1        2           1.0    0.0          0.0                      38.04\n",
            "2        3           1.0    0.0          1.0                       5.00\n",
            "3        4           1.0    0.0          0.0                      50.19\n",
            "4        5           0.0    0.0          0.0                       6.95\n",
            "\n",
            "------------------------------\n",
            "Multi-Output Model Evaluation\n",
            "------------------------------\n",
            "Target: oscillatory?\n",
            "  Accuracy: 71.43%\n",
            "------------------------------\n",
            "Target: noisy\n",
            "  Accuracy: 71.43%\n",
            "------------------------------\n",
            "Target: disturbance\n",
            "  Accuracy: 78.57%\n",
            "------------------------------\n",
            "Target: sticky_valve_probability_\n",
            "  Mean Squared Error: 2143.9691\n",
            "------------------------------\n",
            "Overall Feature Importance (from first estimator):\n",
            "• noise_ratio: 0.2269\n",
            "• error_kurtosis: 0.1688\n",
            "• error_skew: 0.1548\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "# Define feature_names from the available features, excluding non-feature columns\n",
        "feature_names = [\n",
        "    'mse', 'mae', 'error_std', 'noise_metric', 'noise_ratio',\n",
        "    'oscillation_strength', 'error_kurtosis', 'error_skew', 'pv_op_lag'\n",
        "]\n",
        "\n",
        "# Define target columns - these are now multiple\n",
        "target_columns = ['oscillatory?', 'noisy', 'disturbance', 'sticky_valve_probability_']\n",
        "\n",
        "# Create DataFrame for features and targets\n",
        "X_df = pd.DataFrame(merged_df, columns=['loop_no'] + feature_names)\n",
        "train_df = X_df.merge(merged_df[['loop_no'] + target_columns], on='loop_no')\n",
        "\n",
        "# --- Cleaning step: Remove rows with NaN in the target variables ---\n",
        "train_df.dropna(subset=target_columns, inplace=True)\n",
        "\n",
        "print(f\"Training DataFrame ({len(train_df)} samples) with multiple targets:\")\n",
        "print(train_df[['loop_no'] + target_columns].head())\n",
        "\n",
        "# ==========================================\n",
        "# 4. TRAIN MULTI-OUTPUT MODEL\n",
        "# ==========================================\n",
        "X = train_df[feature_names]\n",
        "y = train_df[target_columns]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use GradientBoostingRegressor for multi-output regression\n",
        "# MultiOutputRegressor allows a single model to predict multiple targets independently\n",
        "model = MultiOutputRegressor(estimator=GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ==========================================\n",
        "# 5. RESULTS & INTERPRETATION\n",
        "# ==========================================\n",
        "preds_test = model.predict(X_test)\n",
        "\n",
        "# Convert predictions to DataFrame for easier evaluation\n",
        "preds_test_df = pd.DataFrame(preds_test, columns=target_columns, index=y_test.index)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 30)\n",
        "print(\"Multi-Output Model Evaluation\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Evaluate each target\n",
        "for i, target_col in enumerate(target_columns):\n",
        "    print(f\"Target: {target_col}\")\n",
        "    actual = y_test[target_col]\n",
        "    predicted = preds_test_df[target_col]\n",
        "\n",
        "    if target_col in ['oscillatory?', 'noisy', 'disturbance']:\n",
        "        # For binary classification targets, round predictions and evaluate accuracy\n",
        "        predicted_binary = (predicted > 0.5).astype(int)\n",
        "        acc = accuracy_score(actual, predicted_binary)\n",
        "        print(f\"  Accuracy: {acc*100:.2f}%\")\n",
        "    elif target_col == 'sticky_valve_probability_':\n",
        "        # For regression target, evaluate Mean Squared Error\n",
        "        mse = mean_squared_error(actual, predicted)\n",
        "        print(f\"  Mean Squared Error: {mse:.4f}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# Feature Importance (from the first estimator in MultiOutputRegressor, usually represents average importance)\n",
        "# Note: Feature importances for MultiOutputRegressor are not directly combined,\n",
        "# but we can look at the importance for the first estimator as an example.\n",
        "# If we wanted per-target importance, we would iterate through model.estimators_\n",
        "\n",
        "print(\"Overall Feature Importance (from first estimator):\")\n",
        "first_estimator_importances = model.estimators_[0].feature_importances_ if hasattr(model.estimators_[0], 'feature_importances_') else []\n",
        "if first_estimator_importances.size > 0:\n",
        "    importances = sorted(zip(feature_names, first_estimator_importances), key=lambda x: x[1], reverse=True)\n",
        "    for name, val in importances[:3]:\n",
        "        print(f\"• {name}: {val:.4f}\")\n",
        "else:\n",
        "    print(\"Feature importances not available for the first estimator.\")\n",
        "print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0a2d50a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The `clean_binary_target` function was successfully applied to the 'noisy' and 'disturbance' columns in the description data, converting their values into binary (0 or 1) as required.\n",
        "*   A `MultiOutputRegressor` using `GradientBoostingRegressor` was trained on 70 samples to predict 'oscillatory?', 'noisy', 'disturbance', and 'sticky\\_valve\\_probability\\_'.\n",
        "*   The model achieved moderate accuracy for the binary classification targets:\n",
        "    *   'oscillatory?': 71.43%\n",
        "    *   'noisy': 71.43%\n",
        "    *   'disturbance': 78.57%\n",
        "*   For the regression target, 'sticky\\_valve\\_probability\\_', the model resulted in a Mean Squared Error (MSE) of 2143.9691.\n",
        "*   The most important features from the first estimator were identified as 'noise\\_ratio' (0.2269), 'error\\_kurtosis' (0.1688), and 'error\\_skew' (0.1548).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The Mean Squared Error of approximately 2144 for 'sticky\\_valve\\_probability\\_' suggests the regression model's predictions are not very accurate, indicating a need for further investigation into the feature set or model architecture for this specific target.\n",
        "*   Given the moderate accuracy for binary targets and high MSE for the regression target, consider exploring hyperparameter tuning for the `GradientBoostingRegressor`, experimenting with other regression models (e.g., Random Forest Regressor, XGBoost), or augmenting the dataset with more samples to potentially improve overall model performance.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
